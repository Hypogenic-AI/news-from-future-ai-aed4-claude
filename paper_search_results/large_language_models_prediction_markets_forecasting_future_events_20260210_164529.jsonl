{"title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "year": 2023, "authors": "Alejandro Lopez-Lira, Yuehua Tang", "url": "https://www.semanticscholar.org/paper/d26c55bee1ac6856a20862b0f7b4ff38fa39af50", "relevance": 3, "abstract": "We document the capability of large language models (LLMs) like ChatGPT to predict stock market reactions from news headlines without direct financial training. Using post-knowledge-cutoff headlines, GPT-4 captures initial market responses, achieving approximately 90% portfolio-day hit rates for the non-tradable initial reaction. GPT-4 scores also significantly predict the subsequent drift, especially for small stocks and negative news. Forecasting ability generally increases with model size, suggesting that financial reasoning is an emerging capacity of complex LLMs. Strategy returns decline as LLM adoption rises, consistent with improved price efficiency. To rationalize these findings, we develop a theoretical model that incorporates LLM technology, information-processing capacity constraints, underreaction, and limits to arbitrage.", "citations": 266}
{"title": "Approaching Human-Level Forecasting with Language Models", "year": 2024, "authors": "Danny Halawi, Fred Zhang, Chen Yueh-Han, Jacob Steinhardt", "url": "https://www.semanticscholar.org/paper/59347f86ce9af155266729e4b0301a29c65abf88", "relevance": 3, "abstract": "Forecasting future events is important for policy and decision making. In this work, we study whether language models (LMs) can forecast at the level of competitive human forecasters. Towards this goal, we develop a retrieval-augmented LM system designed to automatically search for relevant information, generate forecasts, and aggregate predictions. To facilitate our study, we collect a large dataset of questions from competitive forecasting platforms. Under a test set published after the knowledge cut-offs of our LMs, we evaluate the end-to-end performance of our system against the aggregates of human forecasts. On average, the system nears the crowd aggregate of competitive forecasters, and in some settings surpasses it. Our work suggests that using LMs to forecast the future could provide accurate predictions at scale and help to inform institutional decision making.", "citations": 59}
{"title": "Wisdom of the silicon crowd: LLM ensemble prediction capabilities rival human crowd accuracy", "year": 2024, "authors": "P. Schoenegger, Indre Tuminauskaite, P. S. Park, P. Tetlock", "url": "https://www.semanticscholar.org/paper/e78188daf9a18840933f3acfc9b3ccfea3db7856", "relevance": 3, "abstract": "Human forecasting accuracy improves through the \u201cwisdom of the crowd\u201d effect, in which aggregated predictions tend to outperform individual ones. Past research suggests that individual large language models (LLMs) tend to underperform compared to human crowd aggregates. We simulate a wisdom of the crowd effect with LLMs. Specifically, we use an ensemble of 12 LLMs to make probabilistic predictions about 31 binary questions, comparing them with those made by 925 human forecasters in a 3-month tournament. We show that the LLM crowd outperforms a no-information benchmark and is statistically indistinguishable from the human crowd. We also observe human-like biases, such as the acquiescence bias. In another study, we find that LLM predictions (of GPT-4 and Claude 2) improve when exposed to the median human prediction, increasing accuracy by 17 to 28%. However, simply averaging human and machine forecasts yields more accurate results. Our findings suggest that LLM predictions can rival the human crowd\u2019s forecasting accuracy through simple aggregation.", "citations": 51}
{"title": "Pitfalls in Evaluating Language Model Forecasters", "year": 2025, "authors": "Daniel Paleka, Shashwat Goel, Jonas Geiping, Florian Tram\u00e8r", "url": "https://api.semanticscholar.org/CorpusId:279075596", "relevance": 3, "abstract": "Large language models (LLMs) have recently been applied to forecasting tasks, with some works claiming these systems match or exceed human performance. In this paper, we argue that, as a community, we should be careful about such conclusions as evaluating LLM forecasters presents unique challenges. We identify two broad categories of issues: (1) difficulty in trusting evaluation results due to many forms of temporal leakage, and (2) difficulty in extrapolating from evaluation performance to real-world forecasting. Through systematic analysis and concrete examples from prior work, we demonstrate how evaluation flaws can raise concerns about current and future performance claims. We argue that more rigorous evaluation methodologies are needed to confidently assess the forecasting abilities of LLMs.", "citations": 7}
{"title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "year": 2025, "authors": "Qingchuan Yang, Simon Mahns, Sida Li, Anri Gu, Jibang Wu, Haifeng Xu", "url": "https://api.semanticscholar.org/CorpusId:282209301", "relevance": 3, "abstract": "Forecasting is not only a fundamental intellectual pursuit but also is of significant importance to societal systems such as finance and economics. With the rapid advances of large language models (LLMs) trained on Internet-scale data, it raises the promise of employing LLMs to forecast real-world future events, an emerging paradigm we call\"LLM-as-a-Prophet\". This paper systematically investigates such predictive intelligence of LLMs. To this end, we build Prophet Arena, a general evaluation benchmark that continuously collects live forecasting tasks and decomposes each task into distinct pipeline stages, in order to support our controlled and large-scale experimentation. Our comprehensive evaluation reveals that many LLMs already exhibit impressive forecasting capabilities, reflected in, e.g., their small calibration errors, consistent prediction confidence and promising market returns. However, we also uncover key bottlenecks towards achieving superior predictive intelligence via LLM-as-a-Prophet, such as LLMs'inaccurate event recalls, misunderstanding of data sources and slower information aggregation compared to markets when resolution nears.", "citations": 2}
{"title": "Text2TimeSeries: Enhancing Financial Forecasting through Time Series Prediction Updates with Event-Driven Insights from Large Language Models", "year": 2024, "authors": "Litton J. Kurisinkel, Pruthwik Mishra, Yue Zhang", "url": "https://api.semanticscholar.org/CorpusId:271039509", "relevance": 3, "abstract": "Time series models, typically trained on numerical data, are designed to forecast future values. These models often rely on weighted averaging techniques over time intervals. However, real-world time series data is seldom isolated and is frequently influenced by non-numeric factors. For instance, stock price fluctuations are impacted by daily random events in the broader world, with each event exerting a unique influence on price signals. Previously, forecasts in financial markets have been approached in two main ways: either as time-series problems over price sequence or sentiment analysis tasks. The sentiment analysis tasks aim to determine whether news events will have a positive or negative impact on stock prices, often categorizing them into discrete labels. Recognizing the need for a more comprehensive approach to accurately model time series prediction, we propose a collaborative modeling framework that incorporates textual information about relevant events for predictions. Specifically, we leverage the intuition of large language models about future changes to update real number time series predictions. We evaluated the effectiveness of our approach on financial market data.", "citations": 8}
{"title": "Can Language Models Use Forecasting Strategies?", "year": 2024, "authors": "Sarah Pratt, Seth Blumberg, Pietro K. Carolino, Meredith Ringel Morris", "url": "https://www.semanticscholar.org/paper/cbdbd93f4f30693ad408e480b2060a5ffda09994", "relevance": 3, "abstract": "Advances in deep learning systems have allowed large models to match or surpass human accuracy on a number of skills such as image classification, basic programming, and standardized test taking. As the performance of the most capable models begin to saturate on tasks where humans already achieve high accuracy, it becomes necessary to benchmark models on increasingly complex abilities. One such task is forecasting the future outcome of events. In this work we describe experiments using a novel dataset of real world events and associated human predictions, an evaluation metric to measure forecasting ability, and the accuracy of a number of different LLM based forecasting designs on the provided dataset. Additionally, we analyze the performance of the LLM forecasters against human predictions and find that models still struggle to make accurate predictions about the future. Our follow-up experiments indicate this is likely due to models' tendency to guess that most events are unlikely to occur (which tends to be true for many prediction datasets, but does not reflect actual forecasting abilities). We reflect on next steps for developing a systematic and reliable approach to studying LLM forecasting.", "citations": 9}
{"title": "Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament", "year": 2023, "authors": "P. Schoenegger, P. S. Park", "url": "https://api.semanticscholar.org/CorpusId:264406226", "relevance": 3, "abstract": "Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence. However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent. To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform. The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict. Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts. We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question. We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis. Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts. A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data. This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.", "citations": 22}
{"title": "Evaluating LLMs on Real-World Forecasting Against Expert Forecasters", "year": 2025, "authors": "Janna Lu", "url": "https://api.semanticscholar.org/CorpusId:280079654", "relevance": 3, "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their ability to forecast future events remains understudied. A year ago, large language models struggle to come close to the accuracy of a human crowd. I evaluate state-of-the-art LLMs on 464 forecasting questions from Metaculus, comparing their performance against top forecasters. Frontier models achieve Brier scores that ostensibly surpass the human crowd but still significantly underperform a group of experts.", "citations": 2}
{"title": "Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts", "year": 2025, "authors": "Sang-Woo Lee, Sohee Yang, Donghyun Kwak, Noah Y. Siegel", "url": "https://api.semanticscholar.org/CorpusId:280045903", "relevance": 3, "abstract": "Many recent papers have studied the development of superforecaster-level event forecasting LLMs. While methodological problems with early studies cast doubt on the use of LLMs for event forecasting, recent studies with improved evaluation methods have shown that state-of-the-art LLMs are gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting. Additionally, the unprecedented success of recent reasoning models and Deep Research-style models suggests that technology capable of greatly improving forecasting performance has been developed. Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems. Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals. For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas. This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers'interest in these directions.", "citations": 2}
{"title": "Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking", "year": 2025, "authors": "Chinmay Karkar, Paras Chopra", "url": "https://api.semanticscholar.org/CorpusId:283244307", "relevance": 3, "abstract": "Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing. We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date. We analyze how context, question type, and external knowledge affect accuracy and calibration, and how adding factual news context modifies belief formation and failure modes. Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.", "citations": 0}
{"title": "Scaling Open-Ended Reasoning to Predict the Future", "year": 2025, "authors": "Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping", "url": "https://api.semanticscholar.org/CorpusId:284350655", "relevance": 3, "abstract": "High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.", "citations": 0}
{"title": "Outcome-based Reinforcement Learning to Predict the Future", "year": 2025, "authors": "Benjamin Turtel, Danny Franklin, Kris Skotheim, Luke Hewitt, Philipp Schoenegger", "url": "https://api.semanticscholar.org/CorpusId:278886755", "relevance": 3, "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has been an effective approach for improving Large Language Models'reasoning in domains such as coding and mathematics. Here, we apply RLVR methods towards forecasting future real-world events - a challenging task for RL due to the very noisy (and delayed) outcomes involved. Using a novel dataset of recent questions from a prediction market, and accompanying relevant news headlines, we show that a compact (14B) reasoning model can be trained to match or surpass the predictive accuracy of frontier models like o1, while greatly improving probabilistic calibration. The model's performance is also practically meaningful: in a Polymarket trading simulation, we estimate that its bets would have yielded a return on investment of over 10% across all questions in the test set. We detail and compare approaches used in training our model, including augmenting our training-data with synthetic prediction questions, guardrails for learning stability, and median prediction sampling at inference-time.", "citations": 4}
{"title": "Do Large Language Models Know What They Don't Know? Kalshibench: A New Benchmark for Evaluating Epistemic Calibration via Prediction Markets", "year": 2025, "authors": "Lukas Nel", "url": "https://api.semanticscholar.org/CorpusId:283934558", "relevance": 3, "abstract": "A well-calibrated model should express confidence that matches its actual accuracy -- when it claims 80\\% confidence, it should be correct 80\\% of the time. While large language models (LLMs) have achieved remarkable performance across diverse tasks, their epistemic calibration remains poorly understood. We introduce \\textbf{KalshiBench}, a benchmark of 300 prediction market questions from Kalshi, a CFTC-regulated exchange, with verifiable real-world outcomes occurring after model training cutoffs. Unlike traditional benchmarks measuring accuracy on static knowledge, KalshiBench evaluates whether models can appropriately quantify uncertainty about genuinely unknown future events. We evaluate five frontier models -- Claude Opus 4.5, GPT-5.2, DeepSeek-V3.2, Qwen3-235B, and Kimi-K2 -- and find \\textbf{systematic overconfidence across all models}. Even the best-calibrated model (Claude Opus 4.5, ECE=0.120) shows substantial calibration errors, while reasoning-enhanced models like GPT-5.2-XHigh exhibit \\emph{worse} calibration (ECE=0.395) despite comparable accuracy. Critically, only one model achieves a positive Brier Skill Score, indicating most models perform worse than simply predicting base rates. Our findings suggest that scaling and enhanced reasoning do not automatically confer calibration benefits, highlighting epistemic calibration as a distinct capability requiring targeted development.", "citations": 0}
{"title": "Assessing Large Language Models in Updating Their Forecasts with New Information", "year": 2025, "authors": "Moy Yuan, Zifeng Ding, Andreas Vlachos", "url": "https://api.semanticscholar.org/CorpusId:281676366", "relevance": 3, "abstract": "Prior work has largely treated future event prediction as a static task, failing to consider how forecasts and the confidence in them should evolve as new evidence emerges. To address this gap, we introduce EVOLVECAST, a framework for evaluating whether large language models appropriately revise their predictions in response to new information. In particular, EVOLVECAST assesses whether LLMs adjust their forecasts when presented with information released after their training cutoff. We use human forecasters as a comparative reference to analyze prediction shifts and confidence calibration under updated contexts. While LLMs demonstrate some responsiveness to new information, their updates are often inconsistent or overly conservative. We further find that neither verbalized nor logits-based confidence estimates consistently outperform the other, and both remain far from the human reference standard. Across settings, models tend to express conservative bias, underscoring the need for more robust approaches to belief updating.", "citations": 0}
{"title": "Macroeconomic Forecasting with Large Language Models", "year": 2024, "authors": "Andrea Carriero, Davide Pettenuzzo, Shubhranshu Shekhar", "url": "https://api.semanticscholar.org/CorpusId:270870786", "relevance": 3, "abstract": "This paper presents a comparative analysis evaluating the accuracy of Large Language Models (LLMs) against traditional macro time series forecasting approaches. In recent times, LLMs have surged in popularity for forecasting due to their ability to capture intricate patterns in data and quickly adapt across very different domains. However, their effectiveness in forecasting macroeconomic time series data compared to conventional methods remains an area of interest. To address this, we conduct a rigorous evaluation of LLMs against traditional macro forecasting methods, using as common ground the FRED-MD database. Our findings provide valuable insights into the strengths and limitations of LLMs in forecasting macroeconomic time series, shedding light on their applicability in real-world scenarios", "citations": 12}
{"title": "TruthTensor: Evaluating LLMs through Human Imitation on Prediction Market under Drift and Holistic Reasoning", "year": 2026, "authors": "Shirin Shahabi, Spencer Graham, Haruna Isah", "url": "https://api.semanticscholar.org/CorpusId:284911224", "relevance": 3, "abstract": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures reasoning models not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly released TruthTensor at https://truthtensor.com.", "citations": 0}
{"title": "PROPHET: An Inferable Future Forecasting Benchmark with Causal Intervened Likelihood Estimation", "year": 2025, "authors": "Zhengwei Tao, Zhi Jin, Bincheng Li, Xiaoying Bai, Haiyan Zhao, Chengfeng Dou, Xiancai Chen, Jia Li, Linyu Li, Chongyang Tao", "url": "https://api.semanticscholar.org/CorpusId:277502489", "relevance": 3, "abstract": "Predicting future events based on news on the Web stands as one of the ultimate aspirations of artificial intelligence. Recent advances in large language model (LLM)-based systems have shown remarkable potential in forecasting future events, thereby garnering significant interest in the research community. Currently, several benchmarks have been established to evaluate the forecasting capabilities by formalizing the event prediction as a retrieval-augmented generation (RAG)-and-reasoning task. In these benchmarks, each prediction question is answered with relevant retrieved news articles downloaded from the Web. However, because there is no consideration of whether the questions can be supported by valid or sufficient supporting rationales, some of the questions in these benchmarks may be inherently noninferable. To address this issue, we introduce a new benchmark, PROPHET, which comprises inferable forecasting questions paired with relevant news for retrieval. To ensure the inferability of the benchmark, we propose Causal Intervened Likelihood (CIL), a statistical measure that assesses inferability through causal inference. In constructing this benchmark, we first collected recent trend forecasting questions, and then filtered the data using CIL resulting in an inferable benchmark for future forecasting. Through extensive experiments, we first demonstrate the validity of CIL and in-depth investigations into future forecasting with the aid of CIL. Subsequently, we evaluate several representative prediction methods on PROPHET. The overall results draws valuable insights for task of future directions.", "citations": 3}
{"title": "AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval", "year": 2023, "authors": "Qi Yan, Raihan Seraj, Jiawei He, Li Meng, Tristan Sylvain", "url": "https://api.semanticscholar.org/CorpusId:263608809", "relevance": 3, "abstract": "Machine-based prediction of real-world events is garnering attention due to its potential for informed decision-making. Whereas traditional forecasting predominantly hinges on structured data like time-series, recent breakthroughs in language models enable predictions using unstructured text. In particular, (Zou et al., 2022) unveils AutoCast, a new benchmark that employs news articles for answering forecasting queries. Nevertheless, existing methods still trail behind human performance. The cornerstone of accurate forecasting, we argue, lies in identifying a concise, yet rich subset of news snippets from a vast corpus. With this motivation, we introduce AutoCast++, a zero-shot ranking-based context retrieval system, tailored to sift through expansive news document collections for event forecasting. Our approach first re-ranks articles based on zero-shot question-passage relevance, honing in on semantically pertinent news. Following this, the chosen articles are subjected to zero-shot summarization to attain succinct context. Leveraging a pre-trained language model, we conduct both the relevance evaluation and article summarization without needing domain-specific training. Notably, recent articles can sometimes be at odds with preceding ones due to new facts or unanticipated incidents, leading to fluctuating temporal dynamics. To tackle this, our re-ranking mechanism gives preference to more recent articles, and we further regularize the multi-passage representation learning to align with human forecaster responses made on different dates. Empirical results underscore marked improvements across multiple metrics, improving the performance for multiple-choice questions (MCQ) by 48% and true/false (TF) questions by up to 8%. Code is available at https://github.com/BorealisAI/Autocast-plus-plus.", "citations": 14}
{"title": "Leveraging Log Probabilities in Language Models to Forecast Future Events", "year": 2025, "authors": "Tommaso Soru, Jim Marshall", "url": "https://api.semanticscholar.org/CorpusId:275405487", "relevance": 3, "abstract": "In the constantly changing field of data-driven decision making, accurately predicting future events is crucial for strategic planning in various sectors. The emergence of Large Language Models (LLMs) marks a significant advancement in this area, offering advanced tools that utilise extensive text data for prediction. In this industry paper, we introduce a novel method for AI-driven foresight using LLMs. Building on top of previous research, we employ data on current trends and their trajectories for generating forecasts on 15 different topics. Subsequently, we estimate their probabilities via a multi-step approach based on log probabilities. We show we achieve a Brier score of 0.186, meaning a +26% improvement over random chance and a +19% improvement over widely-available AI systems.", "citations": 2}
{"title": "A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting", "year": 2024, "authors": "He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua", "url": "https://api.semanticscholar.org/CorpusId:271218811", "relevance": 3, "abstract": "Recently, Large Language Models (LLMs) have demonstrated great potential in various data mining tasks, such as knowledge question answering, mathematical reasoning, and commonsense reasoning. However, the reasoning capability of LLMs on temporal event forecasting has been under-explored. To systematically investigate their abilities in temporal event forecasting, we conduct a comprehensive evaluation of LLM-based methods for temporal event forecasting. Due to the lack of a high-quality dataset that involves both graph and textual data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on this dataset, we design a series of baseline methods, characterized by various input formats and retrieval augmented generation (RAG) modules. From extensive experiments, we find that directly integrating raw texts into the input of LLMs does not enhance zero-shot extrapolation performance. In contrast, fine-tuning LLMs with raw texts can significantly improve performance. Additionally, LLMs enhanced with retrieval modules can effectively capture temporal relational patterns hidden in historical events. However, issues such as popularity bias and the long-tail problem persist in LLMs, particularly in the retrieval-augmented generation (RAG) method. These findings not only deepen our understanding of LLM-based event forecasting methods but also highlight several promising research directions. We consider that this comprehensive evaluation, along with the identified research opportunities, will significantly contribute to future research on temporal event forecasting through LLMs.", "citations": 8}
{"title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures", "year": 2024, "authors": "Mar\u00eda P\u00e9rez-Ortiz", "url": "https://api.semanticscholar.org/CorpusId:274911128", "relevance": 3, "abstract": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term\"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers'ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.", "citations": 9}
{"title": "LLMs Can Teach Themselves to Better Predict the Future", "year": 2025, "authors": "Benjamin Turtel, Danny Franklin, Philipp Schoenegger", "url": "https://api.semanticscholar.org/CorpusId:276249162", "relevance": 3, "abstract": "We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models (LLMs) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization (DPO). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and DeepSeek-R1 14B by between 7--10\\% over a base model and a DPO fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like GPT-4o.", "citations": 4}
{"title": "The Future Outcome Reasoning and Confidence Assessment Benchmark", "year": 2025, "authors": "Moy Yuan, Zifeng Ding, Andreas Vlachos", "url": "https://api.semanticscholar.org/CorpusId:276647821", "relevance": 3, "abstract": "Forecasting is an important task in many domains, such as technology and economics. However existing forecasting benchmarks largely lack comprehensive confidence assessment, focus on limited question types, and often consist of artificial questions that do not align with real-world human forecasting needs. To address these gaps, we introduce FOReCAst (Future Outcome Reasoning and Confidence Assessment), a benchmark that evaluates models' ability to make predictions and their confidence in them. FOReCAst spans diverse forecasting scenarios involving Boolean questions, timeframe prediction, and quantity estimation, enabling a comprehensive evaluation of both prediction accuracy and confidence calibration for real-world applications.", "citations": 4}
{"title": "AIA Forecaster: Technical Report", "year": 2025, "authors": "Rohan Alur, Bradly C. Stadie, Daniel Kang, Ryan Chen, Matt McManus, Michael Rickert, Tyler Lee, Michael Federici, Richard Zhu, Dennis Fogerty, Hayley Williamson, Nina Lozinski, Aaron Linsky, J. Sekhon", "url": "https://api.semanticscholar.org/CorpusId:282922293", "relevance": 3, "abstract": "This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.", "citations": 0}
{"title": "NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with LLMs", "year": 2025, "authors": "Zhaoge Bi, Linghan Huang, Haolin Jin, Qingwen Zeng, Huaming Chen", "url": "https://api.semanticscholar.org/CorpusId:279391458", "relevance": 3, "abstract": "Electricity price forecasting is a critical component of modern energy-management systems, yet existing approaches heavily rely on numerical histories and ignore contemporaneous textual signals. We introduce NSW-EPNews, the first benchmark that jointly evaluates time-series models and large language models (LLMs) on real-world electricity-price prediction. The dataset includes over 175,000 half-hourly spot prices from New South Wales, Australia (2015-2024), daily temperature readings, and curated market-news summaries from WattClarity. We frame the task as 48-step-ahead forecasting, using multimodal input, including lagged prices, vectorized news and weather features for classical models, and prompt-engineered structured contexts for LLMs. Our datasets yields 3.6k multimodal prompt-output pairs for LLM evaluation using specific templates. Through compresive benchmark design, we identify that for traditional statistical and machine learning models, the benefits gain is marginal from news feature. For state-of-the-art LLMs, such as GPT-4o and Gemini 1.5 Pro, we observe modest performance increase while it also produce frequent hallucinations such as fabricated and malformed price sequences. NSW-EPNews provides a rigorous testbed for evaluating grounded numerical reasoning in multimodal settings, and highlights a critical gap between current LLM capabilities and the demands of high-stakes energy forecasting.", "citations": 0}
{"title": "Humans vs Large Language Models: Judgmental Forecasting in an Era of Advanced AI", "year": 2023, "authors": "Mahdi Abolghasemi, Odkhishig Ganbold, Kristian Rotaru", "url": "https://www.semanticscholar.org/paper/c947171b6a6914400de8031d5d9abb66ba6073f9", "relevance": 3, "abstract": "This study investigates the forecasting accuracy of human experts versus Large Language Models (LLMs) in the retail sector, particularly during standard and promotional sales periods. Utilizing a controlled experimental setup with 123 human forecasters and five LLMs, including ChatGPT4, ChatGPT3.5, Bard, Bing, and Llama2, we evaluated forecasting precision through Mean Absolute Percentage Error. Our analysis centered on the effect of the following factors on forecasters performance: the supporting statistical model (baseline and advanced), whether the product was on promotion, and the nature of external impact. The findings indicate that LLMs do not consistently outperform humans in forecasting accuracy and that advanced statistical forecasting models do not uniformly enhance the performance of either human forecasters or LLMs. Both human and LLM forecasters exhibited increased forecasting errors, particularly during promotional periods and under the influence of positive external impacts. Our findings call for careful consideration when integrating LLMs into practical forecasting processes.", "citations": 21}
{"title": "Anticipating the Future with Large Language Models", "year": 2025, "authors": "Tommaso Soru, Jim Marshall", "url": "https://www.semanticscholar.org/paper/f96e051d1672ababf9f290c63823bc94eeda440f", "relevance": 3, "abstract": "In the constantly changing field of data-driven decision making, accurately predicting future events is crucial for strategic planning in various sectors. The emergence of Large Language Models (LLMs) marks a significant advancement in this area, offering advanced tools that utilise extensive text data for prediction. In this industry paper, we introduce a novel method for AI-driven foresight using LLMs. Building on top of previous research, we employ data on current trends and their trajectories to generate forecasts. Subsequently, we estimate their probabilities via a multi-step approach based on logarithmic probabilities. We show we achieve a Brier score of 0.186, meaning a +26% improvement over random chance and a +19% improvement over widely-available AI systems.", "citations": 0}
{"title": "GENERATIVE ARTIFICIAL INTELLIGENCE AND THE FUTURE OF FINANCIAL FORECASTING: EVIDENCE FROM LARGE LANGUAGE MODELS", "year": 2025, "authors": "Mfon NU Akpan", "url": "https://www.semanticscholar.org/paper/b7444edf4d5e16fdd189f6496958f1c7799e73f1", "relevance": 3, "abstract": "The predictive abilities of generative artificial intelligence (AI) are changing the landscape for analytic workflows across sectors. Nevertheless, its capacity and implications for use cases in high-stakes, non-stationary environments \u2014 like financial markets \u2014 have been empirically under-researched (Tan et al., 2023; Lin & Marques, 2024). This research paper examines generative AI\u2019s zero-shot forecasting capabilities using two large language model (LLM) architectures, OpenAI\u2019s GPT-4o, and Anthropic\u2019s Claude 3.5 Sonnet, as they forecast stock prices. Specifically, the paper evaluates the LLMs\u2019 predictive powers in terms of actual closing prices for a portfolio of in-use equities across sectors on February 3, 2025. A rigorous quantitative approach is used throughout the analyses. In the results section, standardized metrics including mean absolute error (MAE), root mean squared error (RMSE), mean absolute percentage error (MAPE), correlation scores, and R-squared are calculated to assess predictive accuracy and directional bias. Results show that Claude 3.5 Sonnet outperformed GPT-4o on all accuracy metrics, and also showed better accuracy in forecasting actual movement in the stock market, confirming the study hypothesis and demonstrating performance can vary significantly between LLM architectures (Xu et al., 2024). Further analysis of sector-based performance can be undertaken. The study concludes that while the LLM Claude 3.5 Sonnet does yield encouraging strategic implications for use in investment analytics, there still exist significant challenges in relation to interpretability, model calibration, and model sensitivity to rapidly changing market dynamics.", "citations": 1}
{"title": "Retrieval-augmented Large Language Models for Financial Time Series Forecasting", "year": 2025, "authors": "Mengxi Xiao, Zihao Jiang, Lingfei Qian, Zhengyu Chen, Yueru He, Yijing Xu, Yuechen Jiang, Dong Li, Ruey-Ling Weng, Min Peng, Jimin Huang, Sophia Ananiadou, Qianqian Xie", "url": "https://www.semanticscholar.org/paper/cf2a6493f7c1eb4632434c89fc659f37b13e7942", "relevance": 3, "abstract": "Accurately forecasting stock price movements is critical for informed financial decision-making, supporting applications ranging from algorithmic trading to risk management. However, this task remains challenging due to the difficulty of retrieving subtle yet high-impact patterns from noisy financial time-series data, where conventional retrieval methods, whether based on generic language models or simplistic numeric similarity, often fail to capture the intricate temporal dependencies and context-specific signals essential for precise market prediction. To bridge this gap, we introduce FinSrag, the first retrieval-augmented generation (RAG) framework with a novel domain-specific retriever FinSeer for financial time-series forecasting. FinSeer leverages a candidate selection mechanism refined by LLM feedback and a similarity-driven training objective to align queries with historically influential sequences while filtering out financial noise. Such training enables FinSeer to identify the most relevant time-series data segments for downstream forecasting tasks, unlike embedding or distance-based retrieval methods used in existing RAG frameworks. The retrieved patterns are then fed into StockLLM, a 1B-parameter LLM fine-tuned for stock movement prediction, which serves as the generative backbone. Beyond the retrieval method, we enrich the retrieval corpus by curating new datasets that integrate a broader set of financial indicators, capturing previously overlooked market dynamics. Experiments demonstrate that FinSeer outperforms existing textual retrievers and traditional distance-based retrieval approaches in enhancing the prediction accuracy of StockLLM, underscoring the importance of domain-specific retrieval frameworks in handling the complexity of financial time-series data.", "citations": 9}
{"title": "Stock Market Forecasting: From Traditional Predictive Models to Large Language Models", "year": 2025, "authors": "Mahmoud Darwish, E. E. Hassanien, Amany H. B. Eissa", "url": "https://www.semanticscholar.org/paper/421dd7c4ad2da83d4b2d95c6f2f15cbffe3c8d73", "relevance": 3, "abstract": "", "citations": 3}
{"title": "Can large language models help predict results from a complex behavioural science study?", "year": 2024, "authors": "Steffen Lippert, Anna Dreber, M. Johannesson, Warren Tierney, Wilson Cyrus-Lai, E. Uhlmann, Thomas Pfeiffer", "url": "https://www.semanticscholar.org/paper/b66855272ab86248e22dac9a6a80752662d232c2", "relevance": 3, "abstract": "We tested whether large language models (LLMs) can help predict results from a complex behavioural science experiment. In study 1, we investigated the performance of the widely used LLMs GPT-3.5 and GPT-4 in forecasting the empirical findings of a large-scale experimental study of emotions, gender, and social perceptions. We found that GPT-4, but not GPT-3.5, matched the performance of a cohort of 119 human experts, with correlations of 0.89 (GPT-4), 0.07 (GPT-3.5) and 0.87 (human experts) between aggregated forecasts and realized effect sizes. In study 2, providing participants from a university subject pool the opportunity to query a GPT-4 powered chatbot significantly increased the accuracy of their forecasts. Results indicate promise for artificial intelligence (AI) to help anticipate\u2014at scale and minimal cost\u2014which claims about human behaviour will find empirical support and which ones will not. Our discussion focuses on avenues for human\u2013AI collaboration in science.", "citations": 14}
{"title": "Application of Large Language Models in Intelligent Preprocessing and Forecasting of Electricity Price", "year": 2025, "authors": "Yutian Huang, Linghan Huang, Yachao Zhu, Gang Lei, Allen Wang, Jianguo Zhu", "url": "https://www.semanticscholar.org/paper/06ebd987825e3a40bec73499df63c0f8bc53465c", "relevance": 3, "abstract": "With the gradual liberalization of global energy markets, accurate electricity price forecasting is crucial for effective system operation and market-oriented reforms\u2014especially for emerging Virtual Power Plants (VPPs) that rely on precise market insights. Traditional forecasting methods often struggle to account for the influence of complex unstructured data, such as news events, on price dynamics. To address this challenge, we propose a novel data preprocessing method that leverages large language models (LLMs) to automatically extract, classify, and derive insights from unstructured news articles (sourced from platforms such as WattClarity), which are then integrated with high-frequency electricity price data. To ensure data consistency, a weighted mean algorithm aggregates price records from 5-minute to 30-minute intervals. Our case study on a multi-source dataset demonstrates that this LLM-based technique not only effectively captures critical market signals from textual data\u2014providing a robust framework for supporting market-driven decision-making for VPPs-but also overcomes the limitations of traditional forecasting approaches by harnessing the unique capabilities of LLMs. The integration of unstructured data processing with precise data aggregation underscores the practical advantages of our approach in modern electricity market applications.", "citations": 1}
{"title": "AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy", "year": 2024, "authors": "P. Schoenegger, P. S. Park, Ezra Karger, Sean Trott, P. Tetlock", "url": "https://www.semanticscholar.org/paper/38472e4242e0aa632ed594c3b0ed9c0bd6429c41", "relevance": 3, "abstract": "Large language models (LLMs) match and sometimes exceed human performance in many domains. This study explores the potential of LLMs to augment human judgment in a forecasting task. We evaluate the effect on human forecasters of two LLM assistants: one designed to provide high-quality (\u201csuperforecasting\u201d) advice, and the other designed to be overconfident and base-rate neglecting, thus providing noisy forecasting advice. We compare participants using these assistants to a control group that received a less advanced model that did not provide numerical predictions or engage in explicit discussion of predictions. Participants (N \\(=\\) 991) answered a set of six forecasting questions and had the option to consult their assigned LLM assistant throughout. Our preregistered analyses show that interacting with each of our frontier LLM assistants significantly enhances prediction accuracy by between 24% and 28% compared to the control group. Exploratory analyses showed a pronounced outlier effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 41%, compared with 29% for the noisy assistant. We further examine whether LLM forecasting augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-the-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty. Our data do not consistently support these hypotheses. Our results suggest that access to a frontier LLM assistant, even a noisy one, can be a helpful decision aid in cognitively demanding tasks compared to a less powerful model that does not provide specific forecasting advice. However, the effects of outliers suggest that further research into the robustness of this pattern is needed.", "citations": 31}
{"title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "year": 2025, "authors": "Deniz Gorur, Antonio Rago, Francesca Toni", "url": "https://www.semanticscholar.org/paper/3544f9f37a760368998d0299f3cea355d605ce4f", "relevance": 3, "abstract": "Judgmental forecasting is the task of making predictions about future events based on human judgment. This task can be seen as a form of claim verification, where the claim corresponds to a future event and the task is to assess the plausibility of that event. In this paper, we propose a novel multi-agent framework for claim verification, whereby different agents may disagree on claim veracity and bring specific evidence for and against the claims, represented as quantitative bipolar argumentation frameworks (QBAFs). We then instantiate the framework for supporting claim verification, with a variety of agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an existing approach for claim verification that generates and evaluates QBAFs; (2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM) from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents, extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of arguments from external sources. Finally, we conduct experiments with two standard judgmental forecasting datasets, with instances of our framework with two or three agents, empowered by six different base LLMs. We observe that combining evidence from agents can improve forecasting accuracy, especially in the case of three agents, while providing an explainable combination of evidence for claim verification.", "citations": 0}
{"title": "Ethereum Price Prediction Employing Large Language Models for Short-term and Few-shot Forecasting", "year": 2025, "authors": "Eftychia Makri, Georgios Palaiokrassas, Sarah Bouraga, Antigoni Polychroniadou, L. Tassiulas", "url": "https://www.semanticscholar.org/paper/95d0b5a14c6b9361b1d12d59c38e4f3cef97c819", "relevance": 3, "abstract": "Cryptocurrencies have transformed financial markets with their innovative blockchain technology and volatile price movements, presenting both challenges and opportunities for predictive analytics. Ethereum, being one of the leading cryptocurrencies, has experienced significant market fluctuations, making its price prediction an attractive yet complex problem. This paper presents a comprehensive study on the effectiveness of Large Language Models (LLMs) in predicting Ethereum prices for short-term and few-shot forecasting scenarios. The main challenge in training models for time series analysis is the lack of data. We address this by leveraging a novel approach that adapts existing pre-trained LLMs on natural language or images from billions of tokens to the unique characteristics of Ethereum price time series data. Through thorough experimentation and comparison with traditional and contemporary models, our results demonstrate that selectively freezing certain layers of pre-trained LLMs achieves state-of-the-art performance in this domain. This approach consistently surpasses benchmarks across multiple metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE), demonstrating its effectiveness and robustness. Our research not only contributes to the existing body of knowledge on LLMs but also provides practical insights in the cryptocurrency prediction domain. The adaptability of pre-trained LLMs to handle the nature of Ethereum prices suggests a promising direction for future research, potentially including the integration of sentiment analysis to further refine forecasting accuracy.", "citations": 2}
{"title": "Argumentatively Coherent Judgmental Forecasting", "year": 2025, "authors": "Deniz Gorur, Antonio Rago, Francesca Toni", "url": "https://www.semanticscholar.org/paper/515a77b9ee3ae2b03ac9aa5a771cfa4ae6901235", "relevance": 3, "abstract": "Judgmental forecasting employs human opinions to make predictions about future events, rather than exclusively historical data as in quantitative forecasting. When these opinions form an argumentative structure around forecasts, it is useful to study the properties of the forecasts from an argumentative perspective. In this paper, we advocate and formally define a property of argumentative coherence, which, in essence, requires that a forecaster's reasoning is coherent with their forecast. We then conduct three evaluations with our notion of coherence. First, we assess the impact of enforcing coherence on human forecasters as well as on Large Language Model (LLM)-based forecasters, given that they have recently shown to be competitive with human forecasters. In both cases, we show that filtering out incoherent predictions improves forecasting accuracy consistently, supporting the practical value of coherence in both human and LLM-based forecasting. Then, via crowd-sourced user experiments, we show that, despite its apparent intuitiveness and usefulness, users do not generally align with this coherence property. This points to the need to integrate, within argumentation-based judgmental forecasting, mechanisms to filter out incoherent opinions before obtaining group forecasting predictions.", "citations": 1}
{"title": "ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities", "year": 2024, "authors": "Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, P. Tetlock", "url": "https://www.semanticscholar.org/paper/a5f8abf651101965fa482e978ab21d9ed175fd78", "relevance": 3, "abstract": "Forecasts of future events are essential inputs into informed decision-making. Machine learning (ML) systems have the potential to deliver forecasts at scale, but there is no framework for evaluating the accuracy of ML systems on a standardized set of forecasting questions. To address this gap, we introduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML systems on an automatically generated and regularly updated set of 1,000 forecasting questions. To avoid any possibility of data leakage, ForecastBench is comprised solely of questions about future events that have no known answer at the time of submission. We quantify the capabilities of current ML systems by collecting forecasts from expert (human) forecasters, the general public, and LLMs on a random subset of questions from the benchmark ($N=200$). While LLMs have achieved super-human performance on many benchmarks, they perform less well here: expert forecasters outperform the top-performing LLM ($p$-value $<0.001$). We display system and human scores in a public leaderboard at www.forecastbench.org.", "citations": 34}
{"title": "LLM-Augmented Linear Transformer\u2013CNN for Enhanced Stock Price Prediction", "year": 2025, "authors": "Lei Zhou, Yuqi Zhang, Jian Yu, Guiling Wang, Zhizhong Liu, Sira Yongchareon, Nancy Wang", "url": "https://www.semanticscholar.org/paper/0133a1bcf4594ffc12e21fc01464258e818f1332", "relevance": 3, "abstract": "Accurately predicting stock prices remains a challenging task due to the volatile and complex nature of financial markets. In this study, we propose a novel hybrid deep learning framework that integrates a large language model (LLM), a Linear Transformer (LT), and a Convolutional Neural Network (CNN) to enhance stock price prediction using solely historical market data. The framework leverages the LLM as a professional financial analyst to perform daily technical analysis. The technical indicators, including moving averages (MAs), relative strength index (RSI), and Bollinger Bands (BBs), are calculated directly from historical stock data. These indicators are then analyzed by the LLM, generating descriptive textual summaries. The textual summaries are further transformed into vector representations using FinBERT, a pre-trained financial language model, to enhance the dataset with contextual insights. The FinBERT embeddings are integrated with features from two additional branches: the Linear Transformer branch, which captures long-term dependencies in time-series stock data through a linearized self-attention mechanism, and the CNN branch, which extracts spatial features from visual representations of stock chart data. The combined features from these three modalities are then processed by a Feedforward Neural Network (FNN) for final stock price prediction. Experimental results on the S&P 500 dataset demonstrate that the proposed framework significantly improves stock prediction accuracy by effectively capturing temporal, spatial, and contextual dependencies in the data. This multimodal approach highlights the importance of integrating advanced technical analysis with deep learning architectures for enhanced financial forecasting.", "citations": 19}
{"title": "Future-as-Label: Scalable Supervision from Real-World Outcomes", "year": 2026, "authors": "Benjamin Turtel, Paul Wilczewski, Danny Franklin, Kris Skothiem", "url": "https://api.semanticscholar.org/CorpusId:284648789", "relevance": 3, "abstract": "Time creates free supervision: forecasts about real-world events resolve to verifiable outcomes. The passage of time provides labels that require no annotation. To exploit this structure, we extend reinforcement learning with verifiable rewards to real-world prediction over time. We train language models to make probabilistic forecasts from causally masked information, using proper scoring rules as the reward function once events resolve. Learning is driven entirely by realized outcomes, enabling scalable outcome-based supervision in open-world prediction. On real-world forecasting benchmarks, Qwen3-32B trained using Foresight Learning improves Brier score by 27% and halves calibration error relative to its pretrained baseline, and outperforms Qwen3-235B on both constructed future-event prediction tasks and the Metaculus benchmark despite a 7x parameter disadvantage.", "citations": 1}
{"title": "Consistency Checks for Language Model Forecasters", "year": 2024, "authors": "Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tram\u00e8r", "url": "https://www.semanticscholar.org/paper/e46a1a8588337600ef5cd591f15b78bcea429f05", "relevance": 3, "abstract": "Forecasting is a task that is difficult to evaluate: the ground truth can only be known in the future. Recent work showing LLM forecasters rapidly approaching human-level performance begs the question: how can we benchmark and evaluate these forecasters instantaneously? Following the consistency check framework, we measure the performance of forecasters in terms of the consistency of their predictions on different logically-related questions. We propose a new, general consistency metric based on arbitrage: for example, if a forecasting AI illogically predicts that both the Democratic and Republican parties have 60% probability of winning the 2024 US presidential election, an arbitrageur can trade against the forecaster's predictions and make a profit. We build an automated evaluation system that generates a set of base questions, instantiates consistency checks from these questions, elicits the predictions of the forecaster, and measures the consistency of the predictions. We then build a standard, proper-scoring-rule forecasting benchmark, and show that our (instantaneous) consistency metrics correlate with LLM forecasters' ground truth Brier scores (which are only known in the future). We also release a consistency benchmark that resolves in 2028, providing a long-term evaluation tool for forecasting.", "citations": 10}
{"title": "StockMem: An Event-Reflection Memory Framework for Stock Forecasting", "year": 2025, "authors": "He Wang, Wenyilin Xiao, Songqiao Han, Hailiang Huang", "url": "https://api.semanticscholar.org/CorpusId:283458534", "relevance": 1, "abstract": "Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.", "citations": 0}
{"title": "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling", "year": 2024, "authors": "Daehoon Gwak, Junwoo Park, Minho Park, chaeHun Park, Hyunchan Lee, Edward Choi, Jaegul Choo", "url": "https://www.semanticscholar.org/paper/c2ef8564b206eb8f61e552a6892052431bdbccf6", "relevance": 1, "abstract": "Predicting future international events from textual information, such as news articles, has tremendous potential for applications in global policy, strategic decision-making, and geopolitics. However, existing datasets available for this task are often limited in quality, hindering the progress of related research. In this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction), a novel dataset designed to address these limitations by leveraging the advanced reasoning capabilities of large-language models (LLMs). Our dataset features high-quality scoring labels generated through advanced prompt modeling and rigorously validated by domain experts in political science. We showcase the quality and utility of WORLDREP for real-world event prediction tasks, demonstrating its effectiveness through extensive experiments and analysis. Furthermore, we publicly release our dataset along with the full automation source code for data collection, labeling, and benchmarking, aiming to support and advance research in text-based event prediction.", "citations": 1}
{"title": "Pre-Finetuning with Impact Duration Awareness for Stock Movement Prediction", "year": 2024, "authors": "Cheng-Chih Chiu, Chung-Chi Chen, Hen-Hsen Huang, Hsin-Hsi Chen", "url": "https://api.semanticscholar.org/CorpusId:272911083", "relevance": 1, "abstract": "Understanding the duration of news events' impact on the stock market is crucial for effective time-series forecasting, yet this facet is largely overlooked in current research. This paper addresses this research gap by introducing a novel dataset, the Impact Duration Estimation Dataset (IDED), specifically designed to estimate impact duration based on investor opinions. Our research establishes that pre-finetuning language models with IDED can enhance performance in text-based stock movement predictions. In addition, we juxtapose our proposed pre-finetuning task with sentiment analysis pre-finetuning, further affirming the significance of learning impact duration. Our findings highlight the promise of this novel research direction in stock movement prediction, offering a new avenue for financial forecasting. We also provide the IDED and pre-finetuned language models under the CC BY-NC-SA 4.0 license for academic use, fostering further exploration in this field.", "citations": 2}
{"title": "From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection", "year": 2024, "authors": "Xinlei Wang, Maike Feng, Jing Qiu, Jinjin Gu, Junhua Zhao", "url": "https://api.semanticscholar.org/CorpusId:273404602", "relevance": 1, "abstract": "This paper introduces a novel approach that leverages Large Language Models (LLMs) and Generative Agents to enhance time series forecasting by reasoning across both text and time series data. With language as a medium, our method adaptively integrates social events into forecasting models, aligning news content with time series fluctuations to provide richer insights. Specifically, we utilize LLM-based agents to iteratively filter out irrelevant news and employ human-like reasoning to evaluate predictions. This enables the model to analyze complex events, such as unexpected incidents and shifts in social behavior, and continuously refine the selection logic of news and the robustness of the agent's output. By integrating selected news events with time series data, we fine-tune a pre-trained LLM to predict sequences of digits in time series. The results demonstrate significant improvements in forecasting accuracy, suggesting a potential paradigm shift in time series forecasting through the effective utilization of unstructured news data.", "citations": 92}
{"title": "Temporal Data Meets LLM - Explainable Financial Time Series Forecasting", "year": 2023, "authors": "Xinli Yu, Zheng Chen, Yuan Ling, Shujing Dong, Zongying Liu, Yanbin Lu", "url": "https://www.semanticscholar.org/paper/681253389d2cc27103753749f4c7556699d55471", "relevance": 1, "abstract": "This paper presents a novel study on harnessing Large Language Models' (LLMs) outstanding knowledge and reasoning abilities for explainable financial time series forecasting. The application of machine learning models to financial time series comes with several challenges, including the difficulty in cross-sequence reasoning and inference, the hurdle of incorporating multi-modal signals from historical news, financial knowledge graphs, etc., and the issue of interpreting and explaining the model results. In this paper, we focus on NASDAQ-100 stocks, making use of publicly accessible historical stock price data, company metadata, and historical economic/financial news. We conduct experiments to illustrate the potential of LLMs in offering a unified solution to the aforementioned challenges. Our experiments include trying zero-shot/few-shot inference with GPT-4 and instruction-based fine-tuning with a public LLM model Open LLaMA. We demonstrate our approach outperforms a few baselines, including the widely applied classic ARMA-GARCH model and a gradient-boosting tree model. Through the performance comparison results and a few examples, we find LLMs can make a well-thought decision by reasoning over information from both textual news and price time series and extracting insights, leveraging cross-sequence information, and utilizing the inherent knowledge embedded within the LLM. Additionally, we show that a publicly available LLM such as Open-LLaMA, after fine-tuning, can comprehend the instruction to generate explainable forecasts and achieve reasonable performance, albeit relatively inferior in comparison to GPT-4.", "citations": 111}
{"title": "GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting", "year": 2024, "authors": "Furong Jia, Kevin Wang, Yixiang Zheng, Defu Cao, Yan Liu", "url": "https://www.semanticscholar.org/paper/34eedbb011e45d80045cadebaf1d01b2ddec22a1", "relevance": 1, "abstract": "Time series forecasting is an essential area of machine learning with a wide range of real-world applications. Most of the previous forecasting models aim to capture dynamic characteristics from uni-modal numerical historical data. Although extra knowledge can boost the time series forecasting performance, it is hard to collect such information. In addition, how to fuse the multimodal information is non-trivial. In this paper, we first propose a general principle of collecting the corresponding textual information from different data sources with the help of modern large language models (LLM). Then, we propose a prompt-based LLM framework to utilize both the numerical data and the textual information simultaneously, named GPT4MTS. In practice, we propose a GDELT-based multimodal time series dataset for news impact forecasting, which provides a concise and well-structured version of time series dataset with textual information for further research in communication. Through extensive experiments, we demonstrate the effectiveness of our proposed method on forecasting tasks with extra-textual information.", "citations": 105}
{"title": "Large Language Models Are Zero-Shot Time Series Forecasters", "year": 2023, "authors": "Nate Gruver, Marc Finzi, Shikai Qiu, Andrew Gordon Wilson", "url": "https://www.semanticscholar.org/paper/123acfbccca0460171b6b06a4012dbb991cde55b", "relevance": 1, "abstract": "By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can surprisingly zero-shot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of LLMs for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how LLMs can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as RLHF.", "citations": 607}
{"title": "Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities", "year": 2024, "authors": "Mingyu Jin, Hua Tang, Chong Zhang, Qinkai Yu, Chengzhi Liu, Suiyuan Zhu, Yongfeng Zhang, Mengnan Du", "url": "https://api.semanticscholar.org/CorpusId:267740358", "relevance": 1, "abstract": "Large language models (LLMs) have been applied in many fields and have developed rapidly in recent years. As a classic machine learning task, time series forecasting has recently been boosted by LLMs. Recent works treat large language models as zero-shot time series reasoners without further fine-tuning, which achieves remarkable performance. However, some unexplored research problems exist when applying LLMs for time series forecasting under the zero-shot setting. For instance, the LLMs' preferences for the input time series are less understood. In this paper, by comparing LLMs with traditional time series forecasting models, we observe many interesting properties of LLMs in the context of time series forecasting. First, our study shows that LLMs perform well in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. This observation can be explained by the ability of LLMs to recognize the underlying period within datasets, which is supported by our experiments. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases substantially improves the predictive performance of LLMs for time series. Our study contributes insight into LLMs' advantages and limitations in time series forecasting under different conditions.", "citations": 71}
{"title": "Are Language Models Actually Useful for Time Series Forecasting?", "year": 2024, "authors": "Mingtian Tan, Mike A. Merrill, Vinayak Gupta, Tim Althoff, Tom Hartvigsen", "url": "https://www.semanticscholar.org/paper/df0d604b8e8e3b2947d9865d735f204c08635012", "relevance": 1, "abstract": "Large language models (LLMs) are being applied to time series forecasting. But are language models actually useful for time series? In a series of ablation studies on three recent and popular LLM-based time series forecasting methods, we find that removing the LLM component or replacing it with a basic attention layer does not degrade forecasting performance -- in most cases, the results even improve! We also find that despite their significant computational cost, pretrained LLMs do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and find that patching and attention structures perform similarly to LLM-based forecasters.", "citations": 179}
{"title": "PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting", "year": 2022, "authors": "Hao Xue, Flora D.Salim", "url": "https://www.semanticscholar.org/paper/863171ed35ca0035074f73bb202b153cc346f2f3", "relevance": 1, "abstract": "This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing SOTA models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting (PromptCast). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset (PISA) that includes three real-world forecasting scenarios. We evaluate different SOTA numerical-based forecasting methods and language generation models. The benchmark results with various forecasting settings demonstrate the proposed PromptCast with language generation models is a promising research direction. Additionally, in comparison to conventional numerical-based forecasting, PromptCast shows a much better generalization ability under the zero-shot setting.", "citations": 276}
{"title": "ChatGPT Informed Graph Neural Network for Stock Movement Prediction", "year": 2023, "authors": "Zihan Chen, Lei Zheng, Chengyu Lu, Jialu Yuan, Di Zhu", "url": "https://www.semanticscholar.org/paper/d3ba770fa1f48458b7ccbc88307b942cfb751a36", "relevance": 1, "abstract": "ChatGPT has demonstrated remarkable capabilities across various natural language processing (NLP) tasks. However, its potential for inferring dynamic network structures from temporal textual data, specifically financial news, remains an unexplored frontier. In this research, we introduce a novel framework that leverages ChatGPT's graph inference capabilities to enhance Graph Neural Networks (GNN). Our framework adeptly extracts evolving network structures from textual data, and incorporates these networks into graph neural networks for subsequent predictive tasks. The experimental results from stock movement forecasting indicate our model has consistently outperformed the state-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios constructed based on our model's outputs demonstrate higher annualized cumulative returns, alongside reduced volatility and maximum drawdown. This superior performance highlights the potential of ChatGPT for text-based network inferences and underscores its promising implications for the financial sector.", "citations": 72}
{"title": "One Fits All: Power General Time Series Analysis by Pretrained LM", "year": 2023, "authors": "Tian Zhou, Peisong Niu, Xue Wang, Liang Sun, Rong Jin", "url": "https://www.semanticscholar.org/paper/5b7f5488c380cf5085a5dd93e993ad293b225eee", "relevance": 1, "abstract": "Although we have witnessed great success of pre-trained models in natural language processing (NLP) and computer vision (CV), limited progress has been made for general time series analysis. Unlike NLP and CV where a unified model can be used to perform different tasks, specially designed approach still dominates in each time series analysis task such as classification, anomaly detection, forecasting, and few-shot learning. The main challenge that blocks the development of pre-trained model for time series analysis is the lack of a large amount of data for training. In this work, we address this challenge by leveraging language or CV models, pre-trained from billions of tokens, for time series analysis. Specifically, we refrain from altering the self-attention and feedforward layers of the residual blocks in the pre-trained language or image model. This model, known as the Frozen Pretrained Transformer (FPT), is evaluated through fine-tuning on all major types of tasks involving time series. Our results demonstrate that pre-trained models on natural language or images can lead to a comparable or state-of-the-art performance in all main time series analysis tasks, as illustrated in Figure 1. We also found both theoretically and empirically that the self-attention module behaviors similarly to principle component analysis (PCA), an observation that helps explains how transformer bridges the domain gap and a crucial step towards understanding the universality of a pre-trained transformer.The code is publicly available at https://github.com/DAMO-DI-ML/One_Fits_All.", "citations": 769}
{"title": "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges", "year": 2024, "authors": "Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Poor, Qingsong Wen, Stefan Zohren", "url": "https://api.semanticscholar.org/CorpusId:270562262", "relevance": 1, "abstract": "Recent advances in large language models (LLMs) have unlocked novel opportunities for machine learning applications in the financial domain. These models have demonstrated remarkable capabilities in understanding context, processing vast amounts of data, and generating human-preferred contents. In this survey, we explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. We provide a discussion of the progress and advantages of LLMs in financial contexts, analyzing their advanced technologies as well as prospective capabilities in contextual understanding, transfer learning flexibility, complex emotion detection, etc. We then highlight this survey for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, agent-based modeling, and other applications. For each application area, we delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, a comprehensive collection of datasets, model assets, and useful codes associated with mainstream applications are presented as resources for the researchers and practitioners. Finally, we outline the challenges and opportunities for future research, particularly emphasizing a number of distinctive aspects in this field. We hope our work can help facilitate the adoption and further development of LLMs in the financial sector.", "citations": 125}
{"title": "Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting", "year": 2023, "authors": "Xinli Yu, Zheng Chen, Yanbin Lu", "url": "https://api.semanticscholar.org/CorpusId:265817515", "relevance": 1, "abstract": ",", "citations": 38}
{"title": "From Deep Learning to LLMs: A survey of AI in Quantitative Investment", "year": 2025, "authors": "Bokai Cao, Sai Wang, Xinyi Lin, Xiaojun Wu, Haohan Zhang, Lionel M. Ni, Jian Guo", "url": "https://api.semanticscholar.org/CorpusId:277349765", "relevance": 1, "abstract": "Quantitative investment (quant) is an emerging, technology-driven approach in asset management, increasingy shaped by advancements in artificial intelligence. Recent advances in deep learning and large language models (LLMs) for quant finance have improved predictive modeling and enabled agent-based automation, suggesting a potential paradigm shift in this field. In this survey, taking alpha strategy as a representative example, we explore how AI contributes to the quantitative investment pipeline. We first examine the early stage of quant research, centered on human-crafted features and traditional statistical models with an established alpha pipeline. We then discuss the rise of deep learning, which enabled scalable modeling across the entire pipeline from data processing to order execution. Building on this, we highlight the emerging role of LLMs in extending AI beyond prediction, empowering autonomous agents to process unstructured data, generate alphas, and support self-iterative workflows.", "citations": 11}
{"title": "Enhancing Few-Shot Stock Trend Prediction with Large Language Models", "year": 2024, "authors": "Yiqi Deng, Xingwei He, Jiahao Hu, Siu-Ming Yiu", "url": "https://api.semanticscholar.org/CorpusId:271162109", "relevance": 1, "abstract": "The goal of stock trend prediction is to forecast future market movements for informed investment decisions. Existing methods mostly focus on predicting stock trends with supervised models trained on extensive annotated data. However, human annotation can be resource-intensive and the annotated data are not readily available. Inspired by the impressive few-shot capability of Large Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome the scarcity of labeled data and make prediction more feasible to investors. Previous works typically merge multiple financial news for predicting stock trends, causing two significant problems when using LLMs: (1) Merged news contains noise, and (2) it may exceed LLMs' input limits, leading to performance degradation. To overcome these issues, we propose a two-step method 'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category, and predict stock trends for individual news instead of merged news. Then we aggregate these predictions using majority voting. The proposed method offers two advantages: (1) Classifying noisy news as irrelevant removes its impact on the final prediction. (2) Predicting for individual news mitigates LLMs' input length limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in CSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot counterparts by around 7%, 4%, and 4%. Furthermore, our proposed method performs on par with state-of-the-art supervised methods.", "citations": 5}
{"title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach", "year": 2024, "authors": "Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan", "url": "https://api.semanticscholar.org/CorpusId:271860143", "relevance": 1, "abstract": "Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates \u2018base factors\u2018, such as financial metric growth and earnings transcripts, with \u2018external factors\u2018, including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted Fl, and Matthews correlation coefficient (M CC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a \u2018Hold\u2019\u2019\u2019\u2019\u2019 option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI -driven financial analysis tools.", "citations": 51}
{"title": "Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review", "year": 2024, "authors": "Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, Junhong Lin", "url": "https://www.semanticscholar.org/paper/ce7a2ea8774b996e7022b3bd712c13b75365fc96", "relevance": 1, "abstract": "This systematic literature review comprehensively examines the application of Large Language Models (LLMs) in forecasting and anomaly detection, highlighting the current state of research, inherent challenges, and prospective future directions. LLMs have demonstrated significant potential in parsing and analyzing extensive datasets to identify patterns, predict future events, and detect anomalous behavior across various domains. However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency. Moreover, this review outlines critical trends that are likely to shape the evolution of LLMs in these fields, including the push toward real-time processing, the importance of sustainable modeling practices, and the value of interdisciplinary collaboration. Conclusively, this review underscores the transformative impact LLMs could have on forecasting and anomaly detection while emphasizing the need for continuous innovation, ethical considerations, and practical solutions to realize their full potential.", "citations": 133}
{"title": "From Text to Time? Rethinking the Effectiveness of the Large Language Model for Time Series Forecasting", "year": 2025, "authors": "Xinyu Zhang, Shanshan Feng, Xutao Li", "url": "https://api.semanticscholar.org/CorpusId:277780960", "relevance": 1, "abstract": "Using pre-trained large language models (LLMs) as the backbone for time series prediction has recently gained significant research interest. However, the effectiveness of LLM backbones in this domain remains a topic of debate. Based on thorough empirical analyses, we observe that training and testing LLM-based models on small datasets often leads to the Encoder and Decoder becoming overly adapted to the dataset, thereby obscuring the true predictive capabilities of the LLM backbone. To investigate the genuine potential of LLMs in time series prediction, we introduce three pre-training models with identical architectures but different pre-training strategies. Thereby, large-scale pre-training allows us to create unbiased Encoder and Decoder components tailored to the LLM backbone. Through controlled experiments, we evaluate the zero-shot and few-shot prediction performance of the LLM, offering insights into its capabilities. Extensive experiments reveal that although the LLM backbone demonstrates some promise, its forecasting performance is limited. Our source code is publicly available in the anonymous repository: https://anonymous.4open.science/r/LLM4TS-0B5C.", "citations": 2}
{"title": "Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data", "year": 2024, "authors": "Kai Kim, Howard Tsai, Rajat Sen, Abhimanyu Das, Zihao Zhou, Abhishek Tanpure, Mathew Luo, Rose Yu", "url": "https://api.semanticscholar.org/CorpusId:273963973", "relevance": 1, "abstract": "Current forecasting approaches are largely unimodal and ignore the rich textual data that often accompany the time series due to lack of well-curated multimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a carefully curated, time-aligned text and time dataset for multimodal forecasting. Our dataset is composed of sequences of numbers and text aligned to timestamps, and includes data from two different domains: climate science and healthcare. Our data is a significant contribution to the rare selection of available multimodal datasets. We also propose the Hybrid Multi-Modal Forecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and time series data using shared embeddings. However, contrary to our expectations, our Hybrid-MMF model does not outperform existing baselines in our experiments. This negative result highlights the challenges inherent in multimodal forecasting. Our code and data are available at https://github.com/Rose-STL-Lab/Multimodal_ Forecasting.", "citations": 21}
{"title": "UrbanGPT: Spatio-Temporal Large Language Models", "year": 2024, "authors": "Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, Chao Huang", "url": "https://www.semanticscholar.org/paper/8cbb814f7f064aa84650614376094e563b532490", "relevance": 1, "abstract": "Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.", "citations": 156}
{"title": "BreakGPT: Leveraging Large Language Models for Predicting Asset Price Surges", "year": 2024, "authors": "Aleksandr Simonyan", "url": "https://api.semanticscholar.org/CorpusId:273963689", "relevance": 1, "abstract": "This paper introduces BreakGPT, a novel large language model (LLM) architecture adapted specifically for time series forecasting and the prediction of sharp upward movements in asset prices. By leveraging both the capabilities of LLMs and Transformer-based models, this study evaluates BreakGPT and other Transformer-based models for their ability to address the unique challenges posed by highly volatile financial markets. The primary contribution of this work lies in demonstrating the effectiveness of combining time series representation learning with LLM prediction frameworks. We showcase BreakGPT as a promising solution for financial forecasting with minimal training and as a strong competitor for capturing both local and global temporal dependencies.", "citations": 0}
{"title": "Leveraging Large Language Models for Discrepancy Value Prediction in Custody Transfer Systems: A Comparative Analysis of Probabilistic and Point Forecasting Approaches", "year": 2025, "authors": "F. Hidayat, A. Nasution, F. Ambia, D. F. Putra, .. Mulyandri", "url": "https://api.semanticscholar.org/CorpusId:277804386", "relevance": 1, "abstract": "Discrepancies in custody transfer systems in the oil and gas industry pose significant financial, regulatory, and operational risks. Accurate prediction of these discrepancies is critical to optimizing operations and minimizing potential losses. This study evaluates the effectiveness of Large Language Models (LLMs), specifically the Chronos-FineTuning Amazon Chronos T5 Small model, alongside statistical, machine learning, and deep learning models, in both probabilistic and point forecasting tasks. The evaluation covers metrics such as Weighted Quantile Loss (WQL), Scaled Quantile Loss (SQL), Mean Absolute Error (MAE), Symmetric Mean Absolute Percentage Error (SMAPE), and Root Mean Square Error (RMSE). The results highlight the superior performance of the Chronos model in both forecasting paradigms, demonstrating its ability to capture uncertainty and deliver precise predictions. This research offers valuable insights into selecting forecasting methodologies to improve custody transfer operations, underscoring the transformative potential of LLMs in industrial applications.", "citations": 1}
{"title": "TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents", "year": 2025, "authors": "Geon Lee, Wenchao Yu, Kijung Shin, Wei Cheng, Haifeng Chen", "url": "https://api.semanticscholar.org/CorpusId:276409254", "relevance": 1, "abstract": "Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75% in F1 score.", "citations": 31}
{"title": "FinArena: A Human-Agent Collaboration Framework for Financial Market Analysis and Forecasting", "year": 2025, "authors": "Congluo Xu, Zhaobin Liu, Ziyang Li", "url": "https://api.semanticscholar.org/CorpusId:276776379", "relevance": 1, "abstract": "To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework. Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction. The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies. The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements. To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data. Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors' individual risk preferences. Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles. These findings highlight FinArena's potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations.", "citations": 7}
{"title": "RiskLabs: Predicting Financial Risk Using Large Language Model based on Multimodal and Multi-Sources Data", "year": 2024, "authors": "Yupeng Cao, Zhi Chen, Prashant Kumar, Qingyun Pei, Yangyang Yu, Haohang Li, Fabrizio Dimino, Lorenzo Ausiello, K. Subbalakshmi, Papa Momar Ndiaye, Haohang Li", "url": "https://api.semanticscholar.org/CorpusId:278326832", "relevance": 1, "abstract": "The integration of Artificial Intelligence (AI) techniques, particularly large language models (LLMs), in finance has garnered increasing academic attention. Despite progress, existing studies predominantly focus on tasks like financial text summarization, question-answering, and stock movement prediction (binary classification), the application of LLMs to financial risk prediction remains underexplored. Addressing this gap, in this paper, we introduce RiskLabs, a novel framework that leverages LLMs to analyze and predict financial risks. RiskLabs uniquely integrates multimodal financial data, including textual and vocal information from Earnings Conference Calls (ECCs), market-related time series data, and contextual news data to improve financial risk prediction. Empirical results demonstrate RiskLabs' effectiveness in forecasting both market volatility and variance. Through comparative experiments, we examine the contributions of different data sources to financial risk assessment and highlight the crucial role of LLMs in this process. We also discuss the challenges associated with using LLMs for financial risk prediction and explore the potential of combining them with multimodal data for this purpose.", "citations": 4}
{"title": "Towards explainable traffic flow prediction with large language models", "year": 2024, "authors": "Xusen Guo, Qiming Zhang, Junyue Jiang, Mingxing Peng, Meixin Zhu, Hao Yang", "url": "https://www.semanticscholar.org/paper/769907cfdf781bf1337b3f17abe1e51e038583e3", "relevance": 1, "abstract": "", "citations": 67}
{"title": "Watermarking Large Language Model-based Time Series Forecasting", "year": 2025, "authors": "Wei Yuan, Chao-Peng Yang, Yu Xing, Tong Chen, Nguyen Quoc Viet Hung, Hongzhi Yin", "url": "https://api.semanticscholar.org/CorpusId:280322961", "relevance": 1, "abstract": "Large Language Model-based Time Series Forecasting (LLMTS) has shown remarkable promise in handling complex and diverse temporal data, representing a significant step toward foundation models for time series analysis. However, this emerging paradigm introduces two critical challenges. First, the substantial commercial potential and resource-intensive development raise urgent concerns about intellectual property (IP) protection. Second, their powerful time series forecasting capabilities may be misused to produce misleading or fabricated deepfake time series data. To address these concerns, we explore watermarking the outputs of LLMTS models, that is, embedding imperceptible signals into the generated time series data that remain detectable by specialized algorithms. We propose a novel post-hoc watermarking framework, Waltz, which is broadly compatible with existing LLMTS models. Waltz is inspired by the empirical observation that time series patch embeddings are rarely aligned with a specific set of LLM tokens, which we term ``cold tokens''. Leveraging this insight, Waltz embeds watermarks by rewiring the similarity statistics between patch embeddings and cold token embeddings, and detects watermarks using similarity z-scores. To minimize potential side effects, we introduce a similarity-based embedding position identification strategy and employ projected gradient descent to constrain the watermark noise within a defined boundary. Extensive experiments using two popular LLMTS models across seven benchmark datasets demonstrate that Waltz achieves high watermark detection accuracy with minimal impact on the quality of the generated time series.", "citations": 0}
{"title": "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models", "year": 2023, "authors": "Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y. Zhang, X. Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, Qingsong Wen", "url": "https://www.semanticscholar.org/paper/16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277", "relevance": 1, "abstract": "Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.", "citations": 757}
{"title": "Navigating Tomorrow: Reliably Assessing Large Language Models Performance on Future Event Prediction", "year": 2025, "authors": "Petraq Nako, Adam Jatowt", "url": "https://api.semanticscholar.org/CorpusId:275458238", "relevance": 1, "abstract": "Predicting future events is an important activity with applications across multiple fields and domains. For example, the capacity to foresee stock market trends, natural disasters, business developments, or political events can facilitate early preventive measures and uncover new opportunities. Multiple diverse computational methods for attempting future predictions, including predictive analysis, time series forecasting, and simulations have been proposed. This study evaluates the performance of several large language models (LLMs) in supporting future prediction tasks, an under-explored domain. We assess the models across three scenarios: Affirmative vs. Likelihood questioning, Reasoning, and Counterfactual analysis. For this, we create a dataset1 by finding and categorizing news articles based on entity type and its popularity. We gather news articles before and after the LLMs training cutoff date in order to thoroughly test and compare model performance. Our research highlights LLMs potential and limitations in predictive modeling, providing a foundation for future improvements.", "citations": 4}
{"title": "Large Language Models in equity markets: applications, techniques, and insights", "year": 2025, "authors": "Aakanksha Jadhav, Vishal Mirza", "url": "https://api.semanticscholar.org/CorpusId:280955402", "relevance": 1, "abstract": "Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.", "citations": 10}
{"title": "AI in Stock Market Forecasting: A Bibliometric Analysis", "year": 2024, "authors": "Hong N.Dao, ChuanYuan Wang, Aoshi Suzuki, Hitomi Sudo, Li Ye, Debopriyo Roy", "url": "https://api.semanticscholar.org/CorpusId:270776742", "relevance": 1, "abstract": "In recent years, the swift progress of artificial intelligence (AI) has significantly influenced trading practices, providing traders with advanced algorithms that improve decision-making and enhance trading strategies, leading to increased profits and reduced risks. The onset of the era of big data has further enriched this field, offering access to extensive financial data, such as historical stock prices, company financial statements, financial news articles, social media sentiments, and macroeconomic indicators\u2014all publicly available. By identifying complex patterns and correlations within this vast data set, deep learning (DL) algorithms have proven their ability to predict stock prices and market trends more accurately than traditional methods. This comprehensive survey aims to provide an insightful examination of various deeplearning models employed in stock market forecasting. The primary objective is to categorize these models into two distinct types: Uni-modal and multimodal models. By exploring the nuances within each category, this literature survey provides a comprehensive understanding of these models\u2019 strengths, applications, and contributions to the constantly evolving research landscape of stock market forecasting. Our survey adopts a systematic approach to categorize and analyze deep-learning models in stock market forecasting. Leveraging established databases and repositories, we will compile a comprehensive dataset comprising academic articles, conference papers, and other scholarly publications related to DL in finance. This dataset will span a defined period, allowing us to capture the temporal evolution of research trends in stock market prediction. The first phase involves extracting and compiling relevant literature from established databases, including but not limited to Scopus, Web of Science, and Google Scholar. This dataset will serve as the foundation for exploring the evolving landscape of DL applications in stock market forecasting. Subsequently, advanced techniques and methodologies will be employed to analyze citation patterns, model co-occurrence, and the intellectual structure of research in this domain. Our research identifies influential authors, collaboration networks, and geographical distribution of research activities to uncover emerging clusters of research excellence. The findings of this survey contribute valuable insights to both academia and industry. By categorizing and examining the strengths of uni-modal and multi-modal deep-learning models, researchers can refine their methodologies, and practitioners can make informed decisions regarding adopting predictive models in financial markets. Furthermore, the survey aims to guide future research directions, enhancing the overall effectiveness of predictive models in the dynamic landscape of stock market forecasting. In conclusion, this survey aims to provide a comprehensive overview of deeplearning models in stock market forecasting. By systematically categorizing and analyzing these models, our study aspires to contribute to the ongoing dialogue on integrating AI in financial practices, fostering a deeper understanding of the field\u2019s evolution and future directions.", "citations": 3}
{"title": "Assessing Look-Ahead Bias in Stock Return Predictions Generated by GPT Sentiment Analysis", "year": 2023, "authors": "P. Glasserman, Caden Lin", "url": "https://api.semanticscholar.org/CorpusId:263310733", "relevance": 1, "abstract": "Large language models (LLMs), including ChatGPT, can extract profitable trading signals from the sentiment in news text. However, backtesting such strategies poses a challenge because LLMs are trained on many years of data, and backtesting produces biased results if the training and backtesting periods overlap. This bias can take two forms: a look-ahead bias, in which the LLM may have specific knowledge of the stock returns that followed a news article, and a distraction effect, in which general knowledge of the companies named interferes with the measurement of a text\u2019s sentiment. The authors investigate these sources of bias through trading strategies driven by the sentiment of financial news headlines. They compare trading performance based on the original headlines with debiased strategies in which they remove the relevant company\u2019s identifiers from the text. In-sample (within the LLM training window), the authors find, surprisingly, that the anonymized headlines outperform, indicating that the distraction effect has a greater impact than look-ahead bias. This tendency is particularly strong for larger companies\u2014companies about which the authors expect an LLM to have greater general knowledge. Out-of-sample, look-ahead bias is not a concern but distraction remains possible. The authors\u2019 proposed anonymization procedure is therefore potentially useful in out-of-sample implementation, as well as for debiased backtesting.", "citations": 23}
{"title": "Domain Specific Benchmarks for Evaluating Multimodal Large Language Models", "year": 2025, "authors": "Khizar Anjum, Muhammad Arbab Arshad, Kadhim Hayawi, Efstathios Polyzos, Asadullah Tariq, M. Serhani, Laiba Batool, Brady D. Lund, Nishith Reddy Mannuru, Ravi Varma Kumar Bevara, Taslim Mahbub, Muhammad Zeeshan Akram, Sakib Shahriar", "url": "https://www.semanticscholar.org/paper/e7b6afd19b2b6e6a76f04ad4fe1a31b3388cfe89", "relevance": 1, "abstract": "Large language models (LLMs) are increasingly being deployed across disciplines due to their advanced reasoning and problem solving capabilities. To measure their effectiveness, various benchmarks have been developed that measure aspects of LLM reasoning, comprehension, and problem-solving. While several surveys address LLM evaluation and benchmarks, a domain-specific analysis remains underexplored in the literature. This paper introduces a taxonomy of seven key disciplines, encompassing various domains and application areas where LLMs are extensively utilized. Additionally, we provide a comprehensive review of LLM benchmarks and survey papers within each domain, highlighting the unique capabilities of LLMs and the challenges faced in their application. Finally, we compile and categorize these benchmarks by domain to create an accessible resource for researchers, aiming to pave the way for advancements toward artificial general intelligence (AGI)", "citations": 3}
{"title": "The evolution, applications, and future prospects of large language models: An in-depth overview", "year": 2024, "authors": "Jiayin Li", "url": "https://api.semanticscholar.org/CorpusId:267402678", "relevance": 1, "abstract": "The evolution of natural language processing has transpired through three primary phases, with large-scale language models significantly transforming the field. These models have heightened the machine's capability to understand, produce, and interact with human language in unprecedented ways. Progressing from RNNs to transformer models, transitioning from encoder-decoder frameworks to decoder-centric designs, and the journey from BERT to the Chat-GPT series have marked significant shifts in the academic discourse. Impressively, these sophisticated models have infiltrated a range of sectors, including finance, healthcare, biology, and education, revolutionizing both traditional and emerging domains. However, as these advancements are celebrated, the ethical and economic challenges they introduce must also be addressed. Confronting these pivotal issues and harnessing technology for societal betterment has become a priority for academia and industry alike, sparking intense research endeavors in recent times. This review dives into the history of natural language processing, highlighting the pivotal developments and core principles of large language models. It provides a comprehensive perspective on their adoption and influence within the financial sector, crafting a detailed narrative of their deployment. In conclusion, the analysis reflects on the current challenges posed by these models and presents potential solutions. This study stands as a definitive guide, offering readers an in-depth understanding of the development, application, and future trajectories of large-scale language models.", "citations": 3}
{"title": "LLMs for Time Series: an Application for Single Stocks and Statistical Arbitrage", "year": 2024, "authors": "S\u00e9bastien Valeyre, Sofiane Aboura", "url": "https://api.semanticscholar.org/CorpusId:274656301", "relevance": 1, "abstract": "Recently, LLMs (Large Language Models) have been adapted for time series prediction with significant success in pattern recognition. However, the common belief is that these models are not suitable for predicting financial market returns, which are known to be almost random. We aim to challenge this misconception through a counterexample. Specifically, we utilized the Chronos model from Ansari et al.(2024) and tested both pretrained configurations and fine-tuned supervised forecasts on the largest American single stocks using data from Guijarro-Ordonnez et al.(2022). We constructed a long/short portfolio, and the performance simulation indicates that LLMs can in reality handle time series that are nearly indistinguishable from noise, demonstrating an ability to identify inefficiencies amidst randomness and generate alpha. Finally, we compared these results with those of specialized models and smaller deep learning models, highlighting significant room for improvement in LLM performance to further enhance their predictive capabilities.", "citations": 2}
{"title": "Bridging Language Models and Financial Analysis", "year": 2025, "authors": "Alejandro Lopez-Lira, Jihoon Kwon, Sangwoong Yoon, Jy-yong Sohn, Chanyeol Choi", "url": "https://api.semanticscholar.org/CorpusId:277451826", "relevance": 1, "abstract": "The rapid advancements in Large Language Models (LLMs) have unlocked transformative possibilities in natural language processing, particularly within the financial sector. Financial data is often embedded in intricate relationships across textual content, numerical tables, and visual charts, posing challenges that traditional methods struggle to address effectively. However, the emergence of LLMs offers new pathways for processing and analyzing this multifaceted data with increased efficiency and insight. Despite the fast pace of innovation in LLM research, there remains a significant gap in their practical adoption within the finance industry, where cautious integration and long-term validation are prioritized. This disparity has led to a slower implementation of emerging LLM techniques, despite their immense potential in financial applications. As a result, many of the latest advancements in LLM technology remain underexplored or not fully utilized in this domain. This survey seeks to bridge this gap by providing a comprehensive overview of recent developments in LLM research and examining their applicability to the financial sector. Building on previous survey literature, we highlight several novel LLM methodologies, exploring their distinctive capabilities and their potential relevance to financial data analysis. By synthesizing insights from a broad range of studies, this paper aims to serve as a valuable resource for researchers and practitioners, offering direction on promising research avenues and outlining future opportunities for advancing LLM applications in finance.", "citations": 5}
{"title": "Multimodal Gen-AI for Fundamental Investment Research", "year": 2023, "authors": "Lezhi Li, Ting-Yu Chang, Hai Wang", "url": "https://api.semanticscholar.org/CorpusId:266977160", "relevance": 1, "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.", "citations": 11}
{"title": "TimeRAG: Boosting LLM Time Series Forecasting via Retrieval-Augmented Generation", "year": 2024, "authors": "Si-Nan Yang, Dong Wang, Haoqi Zheng, Ruochun Jin", "url": "https://www.semanticscholar.org/paper/108a5a16e4e32a3f7cb4d2668e4c6bbee3feb692", "relevance": 1, "abstract": "Although the rise of large language models (LLMs) has introduced new opportunities for time series forecasting, existing LLM-based solutions require excessive training and exhibit limited transferability. In view of these challenges, we propose TimeRAG, a framework that incorporates Retrieval-Augmented Generation (RAG) into time series forecasting LLMs, which constructs a time series knowledge base from historical sequences, retrieves reference sequences from the knowledge base that exhibit similar patterns to the query sequence measured by Dynamic Time Warping (DTW), and combines these reference sequences and the prediction query as a textual prompt to the time series forecasting LLM. Experiments on datasets from various domains show that the integration of RAG improved the prediction accuracy of the original model by 2.97% on average.", "citations": 21}
{"title": "Background-aware Multi-source Fusion Financial Trend Forecasting Mechanism", "year": 2024, "authors": "Fengting Mo, Shanshan Yan, Yinhao Xiao", "url": "https://api.semanticscholar.org/CorpusId:270870736", "relevance": 1, "abstract": "Stock prices, as an economic indicator, reflect changes in economic development and market conditions. Traditional stock price prediction models often only consider time-series data and are limited by the mechanisms of the models themselves. Some deep learning models have high computational costs, depend on a large amount of high-quality data, and have poor interpretations, making it difficult to intuitively understand the driving factors behind the predictions. Some studies have used deep learning models to extract text features and combine them with price data to make joint predictions, but there are issues with dealing with information noise, accurate extraction of text sentiment, and how to efficiently fuse text and numerical data. To address these issues in this paper, we propose a background-aware multi-source fusion financial trend forecasting mechanism. The system leverages a large language model to extract key information from policy and stock review texts, utilizing the MacBERT model to generate feature vectors. These vectors are then integrated with stock price data to form comprehensive feature representations. These integrated features are input into a neural network comprising various deep learning architectures. By integrating multiple data sources, the system offers a holistic view of market dynamics. It harnesses the comprehensive analytical and interpretative capabilities of large language models, retaining deep semantic and sentiment information from policy texts to provide richer input features for stock trend prediction. Additionally, we compare the accuracy of six models (LSTM, BiLSTM, MogrifierLSTM, GRU, ST-LSTM, SwinLSTM). The results demonstrate that our system achieves generally better accuracy in predicting stock movements, attributed to the incorporation of large language model processing, policy information, and other influential features.", "citations": 0}
{"title": "StockTime: A Time Series Specialized Large Language Model Architecture for Stock Price Prediction", "year": 2024, "authors": "Shengkun Wang, Taoran Ji, Linhan Wang, Yanshen Sun, Shang-Ching Liu, Amit Kumar, Chang-Tien Lu", "url": "https://api.semanticscholar.org/CorpusId:272653967", "relevance": 1, "abstract": "The stock price prediction task holds a significant role in the financial domain and has been studied for a long time. Recently, large language models (LLMs) have brought new ways to improve these predictions. While recent financial large language models (FinLLMs) have shown considerable progress in financial NLP tasks compared to smaller pre-trained language models (PLMs), challenges persist in stock price forecasting. Firstly, effectively integrating the modalities of time series data and natural language to fully leverage these capabilities remains complex. Secondly, FinLLMs focus more on analysis and interpretability, which can overlook the essential features of time series data. Moreover, due to the abundance of false and redundant information in financial markets, models often produce less accurate predictions when faced with such input data. In this paper, we introduce StockTime, a novel LLM-based architecture designed specifically for stock price data. Unlike recent FinLLMs, StockTime is specifically designed for stock price time series data. It leverages the natural ability of LLMs to predict the next token by treating stock prices as consecutive tokens, extracting textual information such as stock correlations, statistical trends and timestamps directly from these stock prices. StockTime then integrates both textual and time series data into the embedding space. By fusing this multimodal data, StockTime effectively predicts stock prices across arbitrary look-back periods. Our experiments demonstrate that StockTime outperforms recent LLMs, as it gives more accurate predictions while reducing memory usage and runtime costs.", "citations": 12}
{"title": "Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study", "year": 2024, "authors": "Chenghao Liu, Arunkumar Arulappan, R. Naha, Aniket Mahanti, J. Kamruzzaman, In-Ho Ra", "url": "https://api.semanticscholar.org/CorpusId:272025780", "relevance": 1, "abstract": "This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin\u2019s longer-term price than immediate news events. This highlights LLMs\u2019 potential in market trend prediction and informed investment decision-making.", "citations": 20}
{"title": "The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges", "year": 2023, "authors": "Qianqian Xie, Weiguang Han, Yanzhao Lai, Min Peng, Jimin Huang", "url": "https://www.semanticscholar.org/paper/ef4cb88b1635b34af15059567dfdf134f79797aa", "relevance": 1, "abstract": "Recently, large language models (LLMs) like ChatGPT have demonstrated remarkable performance across a variety of natural language processing tasks. However, their effectiveness in the financial domain, specifically in predicting stock market movements, remains to be explored. In this paper, we conduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal stock movement prediction, on three tweets and historical stock price datasets. Our findings indicate that ChatGPT is a\"Wall Street Neophyte\"with limited success in predicting stock movements, as it underperforms not only state-of-the-art methods but also traditional methods like linear regression using price features. Despite the potential of Chain-of-Thought prompting strategies and the inclusion of tweets, ChatGPT's performance remains subpar. Furthermore, we observe limitations in its explainability and stability, suggesting the need for more specialized training or fine-tuning. This research provides insights into ChatGPT's capabilities and serves as a foundation for future work aimed at improving financial market analysis and prediction by leveraging social media sentiment and historical stock data.", "citations": 75}
{"title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "year": 2025, "authors": "Mohammadmahdi Ghasemloo, Alireza Moradi", "url": "https://www.semanticscholar.org/paper/cad8c1484b8e41588d305eb9ae6872655335c22f", "relevance": 1, "abstract": "With the widespread adoption of Large Language Models (LLMs), there is a growing need to establish best practices for leveraging their capabilities beyond traditional natural language tasks. In this paper, a novel cross-domain knowledge transfer framework is proposed to enhance the performance of LLMs in time series forecasting -- a task of increasing relevance in fields such as energy systems, finance, and healthcare. The approach systematically infuses LLMs with structured temporal information to improve their forecasting accuracy. This study evaluates the proposed method on a real-world time series dataset and compares it to a naive baseline where the LLM receives no auxiliary information. Results show that knowledge-informed forecasting significantly outperforms the uninformed baseline in terms of predictive accuracy and generalization. These findings highlight the potential of knowledge transfer strategies to bridge the gap between LLMs and domain-specific forecasting tasks.", "citations": 0}
{"title": "Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding", "year": 2024, "authors": "Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, Tat-Seng Chua", "url": "https://www.semanticscholar.org/paper/5aad568d4f02b09af3c282b1f4c20ee0993bc2e6", "relevance": 1, "abstract": "The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for swift and precise analysis of complex events. We refer to the complex events composed of many news articles over an extended period as Temporal Complex Event (TCE). This paper proposes a novel approach using Large Language Models (LLMs) to systematically extract and analyze the event chain within TCE, characterized by their key points and timestamps. We establish a benchmark, named TCELongBench, to evaluate the proficiency of LLMs in handling temporal dynamics and understanding extensive text. This benchmark encompasses three distinct tasks - reading comprehension, temporal sequencing, and future event forecasting. In the experiment, we leverage retrieval-augmented generation (RAG) method and LLMs with long context window to deal with lengthy news articles of TCE. Our findings indicate that models with suitable retrievers exhibit comparable performance with those utilizing long context window.", "citations": 28}
{"title": "BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting", "year": 2025, "authors": "Shiqiao Zhou, Holger Sch\u00f6ner, Huanbo Lyu, Edouard Fouch'e, Shuo Wang", "url": "https://api.semanticscholar.org/CorpusId:281079776", "relevance": 1, "abstract": "Time series forecasting is a long-standing and highly challenging research topic. Recently, driven by the rise of large language models (LLMs), research has increasingly shifted from purely time series methods toward harnessing textual modalities to enhance forecasting performance. However, the vast discrepancy between text and temporal data often leads current multimodal architectures to over-emphasise one modality while neglecting the other, resulting in information loss that harms forecasting performance. To address this modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment for LLM-Based Time Series Forecasting), a lightweight time series forecasting framework that maintains balance between the two modalities. Specifically, raw time series are processed by the time series encoder, while descriptive statistics of raw time series are fed to an LLM with learnable prompt, producing compact textual embeddings. To ensure balanced cross-modal context alignment of time series and textual embeddings, a simple yet effective scaling strategy combined with a contrastive objective then maps these textual embeddings into the latent space of the time series embeddings. Finally, the aligned textual semantic embeddings and time series embeddings are together integrated for forecasting. Extensive experiments on standard benchmarks show that, with minimal trainable parameters, BALM-TSF achieves state-of-the-art performance in both long-term and few-shot forecasting, confirming its ability to harness complementary information from text and time series. Code is available at https://github.com/ShiqiaoZhou/BALM-TSF.", "citations": 1}
{"title": "Large language model-driven time-series forecasting of financial network indicators", "year": 2026, "authors": "Mini Han Wang, Ying Yeung", "url": "https://www.semanticscholar.org/paper/cc70f12544548688aad5b33c3c8b2b7ed5a90326", "relevance": 1, "abstract": "\n \n Financial markets operate as dynamic networks in which institutional cross-holdings shape the diffusion of information and the propagation of risk. Forecasting the evolution of stock information networks is critical for anticipating herding behavior and safeguarding systemic stability, yet remains challenging due to high-dimensional heterogeneity, structural non-stationarity, and the need for economically interpretable predictions.\n \n \n \n Using a quarterly fund\u2013stock holding panel from 2016 to 2024, we construct time-indexed bipartite fund\u2013stock graphs and project them onto the stock layer. From these graphs, we compute two key network indicators: degree centralization (cen_d), capturing market-wide concentration, and residual density (den), reflecting firm-level anomalies. We then develop a large language model (LLM)\u2013enhanced forecasting framework that transforms numeric time series and textual fund disclosures into promptable sequences, incorporates retrieval-augmented historical context, and performs multi-step forecasting of both cen_d and abnormal den spikes.\n \n \n \n Extensive experiments show that the proposed LLM-based framework significantly reduces mean absolute error and root mean square error, and improves directional accuracy, compared with ARIMA, Prophet, and Temporal Fusion Transformer benchmarks. Attention-weight analysis further indicates that the model assigns higher importance to historical quarters characterized by sharp fund co-movement or policy shocks.\n \n \n \n These findings demonstrate that LLM-driven time-series forecasting can provide early warnings of systemic risk and generate economically interpretable insights for investors and regulators. The results highlight the broader potential of language-informed graph forecasting as a new paradigm for financial market surveillance and policy design.\n", "citations": 0}
{"title": "Large Language Models as Interpolated and Extrapolated Event Predictors", "year": 2024, "authors": "Libo Zhang, Yue Ning", "url": "https://www.semanticscholar.org/paper/aeda5438b25a81c18ff12d60141e156ecd8035ea", "relevance": 1, "abstract": "Salient facts of sociopolitical events are distilled into quadruples following a format of subject, relation, object, and timestamp. Machine learning methods, such as graph neural networks (GNNs) and recurrent neural networks (RNNs), have been built to make predictions and infer relations on the quadruple-based knowledge graphs (KGs). In many applications, quadruples are extended to quintuples with auxiliary attributes such as text summaries that describe the quadruple events. In this paper, we comprehensively investigate how large language models (LLMs) streamline the design of event prediction frameworks using quadruple-based or quintuple-based data while maintaining competitive accuracy. We propose LEAP, a unified framework that leverages large language models as event predictors. Specifically, we develop multiple prompt templates to frame the object prediction (OP) task as a standard question-answering (QA) task, suitable for instruction fine-tuning with an encoder-decoder LLM. For multi-event forecasting (MEF) task, we design a simple yet effective prompt template for each event quintuple. This novel approach removes the need for GNNs and RNNs, instead utilizing an encoder-only LLM to generate fixed intermediate embeddings, which are processed by a customized downstream head with a self-attention mechanism to predict potential relation occurrences in the future. Extensive experiments on multiple real-world datasets using various evaluation metrics validate the effectiveness of our approach.", "citations": 3}
{"title": "Prompt-Driven Time Series Forecasting with Large Language Models", "year": 2025, "authors": "Zairo Bastos, J. Freitas, Jos\u00e9 Wellington Franco da Silva, Carlos Caminha", "url": "https://www.semanticscholar.org/paper/c2fa39a609b82307ac3d9d461001e4bc254f19c9", "relevance": 1, "abstract": ": Time series forecasting with machine learning is critical across various fields, with Ensemble models and Neural Networks commonly used to predict future values. LSTM and Transformers architecture excel in modeling complex patterns, while Random Forest has shown strong performance in univariate time series forecasting. With the advent of Large Language Models (LLMs), new opportunities arise for their application in time series prediction. This study compares the forecasting performance of Gemini 1.5 PRO against Random Forest and LSTM using 40 time series from the Retail and Mobility domains, totaling 65,940 time units, evaluated with SMAPE. Results indicate that Gemini 1.5 PRO outperforms LSTM by approximately 4% in Retail and 6.5% in Mobility, though it underperforms Random Forest by 5.5% in Retail and 1% in Mobility. In addition to this comparative analysis, the article contributes a novel prompt template designed specifically for time series forecasting, providing a practical tool for future research and applications.", "citations": 6}
{"title": "Exploring large language models for climate forecasting", "year": 2025, "authors": "Yang Wang, Hassan A. Karimi", "url": "https://www.semanticscholar.org/paper/54647dbb944a4425c83b74ecda6602694953a7eb", "relevance": 1, "abstract": "With the increasing impacts of climate change, there is a growing demand for accessible tools that can provide reliable future climate information to support planning, finance, and other decision-making applications. Large language models (LLMs), such as GPT-4o, present a promising approach to bridging the gap between complex climate data and the general public, offering a way for non-specialist users to obtain essential climate insights through natural language interaction. However, an essential challenge remains underexplored: Evaluating the ability of LLMs to provide accurate and reliable future climate predictions, which is crucial for applications that rely on anticipating climate trends. In this study, we investigated the capability of GPT-4o in predicting rainfall at short-term (15-day) and long-term (12-month) scales. We designed a series of experiments to assess GPT's performance under different conditions, including scenarios with and without expert data inputs. Our results indicated that GPT, when operating independently, tended to generate conservative forecasts, often reverting to historical averages in the absence of clear trend signals. This study highlights the potential and challenges of applying LLMs for future climate predictions, providing insights into their integration with climate-related applications and indicating directions for enhancing their predictive capabilities in the field.", "citations": 1}
{"title": "Empirical Evaluation of Large Language Models for Asset\u2011Return Prediction", "year": 2025, "authors": "Bingxing Wang", "url": "https://www.semanticscholar.org/paper/f3f6baef5ca75d085f3a922f11595917fbb9f5cf", "relevance": 1, "abstract": "In an era of exploding financial\u2010market information and rapid algorithmic iteration, traditional asset\u2011return forecasting models struggle to exploit unstructured text. Using cross\u2011asset data\u2014equities, Treasuries and commodity futures\u2014from 2004\u202fto\u202f2024, we build an integrated prediction framework that fuses semantic factors extracted by Large Language Models (LLMs) with price\u2011volume and macro\u2011numerical factors. We benchmark it against Logit, Random Forest, LightGBM and bidirectional LSTM. A comprehensive evaluation with weighted F\u2081, ROC\u2011AUC, Information Ratio and Sharpe Ratio shows that (i) LLM\u2011based semantic factors significantly improve directional accuracy (F\u2081 +\u202f20.5\u202f%, ROC\u2011AUC +\u202f11.9\u202f%); (ii) after a 3 bp transaction cost, the LLM\u2011driven long\u2013short portfolio achieves annualised information and Sharpe ratios of 0.96 and 1.17, markedly outperforming all baselines; (iii) robustness checks confirm this edge across high\u2011volatility regimes, asset classes and text\u2011lag scenarios; and (iv) the combination of SHAP and attention visualisation traces keyword\u2011level contributions, enhancing interpretability. Our results provide reproducible, quantifiable evidence for large\u2011scale LLM deployment in quantitative investing and point to future work on model compression, slippage estimation and multimodal extension.", "citations": 6}
{"title": "A survey on the application and research progress of large language models in financial forecasting", "year": 2025, "authors": "Ruonan Wu, Hong Liu", "url": "https://www.semanticscholar.org/paper/bec39113be00be96e0f8cd46209a17f9f5f453e8", "relevance": 1, "abstract": "Large language models (LLMs) are reshaping the technical paradigms of financial forecasting through their robust representation learning and reasoning capabilities. This paper systematically reviews the application pathways of architectures such as transformers and graph neural networks in scenarios like stock prediction and risk management, highlighting key technologies for enhancing prediction accuracy through knowledge injection and temporal modeling improvements. The study reveals that LLMs demonstrate significant advantages in unstructured data processing and cross-market correlation analysis but face challenges related to economic logic interpretability and data non-stationarity. Future research should focus on advancing causal reasoning augmentation and federated learning collaboration to achieve secure and trustworthy evolution of financial forecasting systems.", "citations": 0}
{"title": "Review on Large Language Models in Finance: Text and Time Series Analysis for Investor Behavior and Market Prediction", "year": 2025, "authors": "Saeede Anbaee Farimani, Raheleh Ghouchannezhad Noor Nia, Majid Vafaei Jahan", "url": "https://www.semanticscholar.org/paper/7482ab838fe0c0900f575ffedc1a1609388d73f7", "relevance": 1, "abstract": "The onset of social media venues, online news media, and digital content allowed a vast volume of text and time series data to be generated which plays significant role in investors' decision-making and financial market volatility. Data extracted from these platforms provide information on public sentiments, immediate reactions to news, and informal analyses, which, if processed appropriately, can be very useful indicators in forecasting financial market trends. Billions of dollars are invested and lost, depending on correct forecasting. However, advances in deep learning, especially in large language models (LLMs) and novel time series analysis algorithms, have opened new windows to processing and analyzing this complex data. The advanced language models identify hidden patterns and nonlinear dependencies, always taking into account the context and semantic details of the text between news,", "citations": 0}
{"title": "Fusing Large Language Models with Temporal Transformers for Time Series Forecasting", "year": 2025, "authors": "Chen Su, Yuanhe Tian, Qinyu Liu, Jun Zhang, Yan Song", "url": "https://www.semanticscholar.org/paper/f164568919b89ab3bfb05b1ebc9995427de4c4e7", "relevance": 1, "abstract": "Recently, large language models (LLMs) have demonstrated powerful capabilities in performing various tasks and thus are applied by recent studies to time series forecasting (TSF) tasks, which predict future values with the given historical time series. Existing LLM-based approaches transfer knowledge learned from text data to time series prediction using prompting or fine-tuning strategies. However, LLMs are proficient at reasoning over discrete tokens and semantic patterns but are not initially designed to model continuous numerical time series data. The gaps between text and time series data lead LLMs to achieve inferior performance to a vanilla Transformer model that is directly trained on TSF data. However, the vanilla Transformers often struggle to learn high-level semantic patterns. In this paper, we design a novel Transformer-based architecture that complementarily leverages LLMs and vanilla Transformers, so as to integrate the high-level semantic representations learned by LLMs into the temporal information encoded by time series Transformers, where a hybrid representation is obtained by fusing the representations from the LLM and the Transformer. The resulting fused representation contains both historical temporal dynamics and semantic variation patterns, allowing our model to predict more accurate future values. Experiments on benchmark datasets demonstrate the effectiveness of the proposed approach.", "citations": 3}
{"title": "Combining Financial Data and News Articles for Stock Price Movement Prediction Using Large Language Models", "year": 2024, "authors": "Ali Elahi, Fatemeh Taghvaei", "url": "https://www.semanticscholar.org/paper/fdbdae64864e52929adaada64eb8124c68afd374", "relevance": 1, "abstract": "Predicting financial markets and stock price movements requires analyzing a company\u2019s performance, historic price movements, industry-specific events alongside the influence of human factors such as social media and press coverage. We assume that financial reports (such as income statements, balance sheets, and cash flow statements), historical price data, and recent news articles can collectively represent aforementioned factors.We combine financial data in tabular format with textual news articles and employ pre-trained Large Language Models (LLMs) to predict market movements. Recent research in LLMs has demonstrated that they are able to perform both tabular and text classification tasks, making them our primary model to classify the multi-modal data. We utilize retrieval augmentation techniques to retrieve and attach relevant chunks of news articles to financial metrics related to a company and prompt the LLMs in zero, two, and four-shot settings. Our dataset contains news articles collected from different sources, historic stock price, and financial report data for 20 companies with the highest trading volume across different industries in the stock market. We utilized recently released language models for our LLM-based classifier, including GPT- 3 and 4, and LLaMA- 2 and 3 models.We introduce an LLM-based classifier capable of performing classification tasks using combination of tabular (structured) and textual (unstructured) data. By using this model, we predicted the movement of a given stock\u2019s price in our dataset with a weighted F1-score of 58.5% and 59.1% and Matthews Correlation Coefficient of 0.175 for both 3-month and 6-month periods.The dataset and codes for this paper can be found on Github. https://github.com/aliielahi/FinedFMP 1", "citations": 8}
{"title": "FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness", "year": 2025, "authors": "Yuanjian Xu, Jianing Hao, Kunsheng Tang, Jingnan Chen, Anxian Liu, Peng Liu, Guang Zhang", "url": "https://www.semanticscholar.org/paper/ae31ca9344da43928a894bf9641b199290a109f6", "relevance": 1, "abstract": "Financial markets exhibit complex dynamics where localized events trigger ripple effects across entities. Previous event studies, constrained by static single-company analyses and simplistic assumptions, fail to capture these ripple effects. While large language models (LLMs) offer emergent reasoning capabilities, their direct application falters due to structural market unawareness and limited capacity to analyze ripple effects. We propose FinRipple, an elegant framework that empowers LLMs with the ability to analyze ripple effects through financial theory-guided large-scale reinforcement learning. We begin by relaxing the assumptions of previous methods, incorporating a time-varying knowledge graph to accurately represent market structure. By seamlessly integrating classical asset pricing theory, we align the LLM with the market, enabling it to predict ripple effects. To the best of our knowledge, we are the first to provide a standardized definition of ripple effect prediction, a task that is extremely important yet unexplored in the financial domain. Extensive experiments demonstrate that FinRipple provides a promising solution to this task.", "citations": 4}
{"title": "Harnessing Large Language Models for Temporal Knowledge Graph Forecasting with Multi-view Prompting", "year": 2024, "authors": "Da Zhang, Tong Xu, Fake Lin, Jiayue Chen", "url": "https://www.semanticscholar.org/paper/92894bd9f9e68b4e5b2939f59e016756e01ae516", "relevance": 1, "abstract": "In recent years, Temporal Knowledge Graphs (TKGs) have attracted considerable attention from researchers. An important research direction is forecasting future events in TKGs based on historical information, i.e. TKG forecasting. Existing methods primarily rely on modeling temporal relationships between entity IDs to make predictions, which brings limitations in understanding the entity content and the relationships between entities. Fortunately, the emergence of Large Language Models (LLMs) has brought new insights into solving this problem. In this paper, we propose a novel LLM-enhAnced TKG forEcasting (LATE) model. Specifically, we first design multi-view prompts that enable LLMs to generate comprehensive descriptions for entities as external knowledge. Then, we get the enhanced representations of entities based on the descriptions and we further design a contrastive learning strategy to reinforce this process. Finally, we construct a TKG forecasting model based on self-attention mechanisms and dual-pattern LSTM-based temporal modeling to accomplish the forecasting task. Experiments on three datasets demonstrate the effectiveness and superiority of our model compared with several state-of-the-art baseline methods.", "citations": 1}
{"title": "Large Language Models for Smarter Market Sentiment and Trend Prediction", "year": 2025, "authors": "Dr. C. Bhuvaneshwari", "url": "https://www.semanticscholar.org/paper/877f614dc745d8060f9b69ee3986b660ed12319f", "relevance": 1, "abstract": "The fast development of financial sectors has provided an enormous amount of unstructured data which ranges from\nthe organization files, reports collected by the analyst for the social media discussion and the real-time news. Thus, collecting the\nuseful information is very complex task for traders, financial organizations and the investors. The current advancements in the\nLarge Language Models (LLMs) provides a promising way forward. LLM understands the tone, context and other hidden\nsignals inside the text. It can also identify the market sentiment and enhances the trend prediction accuracy. In the traditional\nmodels, the dictionaries which are predefined will be considered or it uses the shallow statistical methods, but in LLM it offers a\nricher insight by identifying the subtle changes in the investor sentiment and uncovers the potential risks or opportunities. This\nresearch examines how the LLMs will be used for the financial sentiment analysis and the trend forecasting by reviewing the\ncore architectures, benchmark datasets and various evaluation strategies. It also points out the specific challenges such as biased\ndata, privacy concerns and regulatory compliance. once these challenges are addressed, LLM-powered systems have the\npotential to provide smarter, more adaptive, and human-like financial insights, enabling faster and more confident decisionmaking in dynamic market environments. To demonstrate the proposed approach, the Financial Phrase Bank dataset will be\nconsidered for implementation, with the aim of evaluating LLM-based models against traditional approaches and showcasing\nmeasurable improvements in sentiment detection and trend prediction accuracy.", "citations": 0}
{"title": "Next timestamp prediction in business process monitoring using large language models", "year": 2025, "authors": "Yifei Xu, Huan Fang", "url": "https://www.semanticscholar.org/paper/e1c059ac5595337f335779df1ec2e8eb959cbb8a", "relevance": 1, "abstract": "Predictive business process monitoring is a critical domain within process mining, with the primary goal of forecasting characteristics of the next event or the remaining time for process executions. Large language models (LLMs) such as Generative Pretrained Transformer (GPT) and Tongyi Qianwen (Qwen) have demonstrated exceptional performance in natural language processing but face challenges when applied to process data prediction. This paper introduces LLM4NT, which leverages the decoder component of the Qwen 2.5-0.5B model as its backbone. By employing a multi-head cross-attention mechanism, it reprograms process data and textual information, aligning process and text modalities to achieve precise predictions of the next timestamp in predictive monitoring. Experimental results on multiple real-life event logs demonstrate that LLM4NT achieves state-of-the-art average performance in next-timestamp prediction tasks, showcasing its powerful capabilities in business process reasoning.", "citations": 2}
{"title": "Large Language Models (LLMs) for Network Traffic Prediction: A Trend-Aware Hybrid Framework", "year": 2026, "authors": "Yuzhou Chen, Kwok-Yan Lam, Feng Li", "url": "https://www.semanticscholar.org/paper/34662a17f23a9fb217712f1edd3a6b4483778f41", "relevance": 1, "abstract": "The explosive growth and increasing complexity of modern 5G/6G networks, driven by Internet of Things (IoT), industrial automation, and real-time multimedia streaming, demand forecasting methods that address nonstationarity, abrupt shifts, and incomplete observations. Nonstationarity involves changing statistical properties, abrupt shifts stem from events or outages, and data gaps can impair model accuracy. Traditional statistical models and deep sequence learners partially handle these challenges but often leave systematic residuals, which are structured errors from unmodeled scenarios and overlook high-level contextual cues such as external events or semantic patterns. To overcome these limitations, we propose a hybrid forecasting framework combining a convolutional neural network-long short-term memory (CNN-LSTM) trend predictor for capturing local fluctuations and long-range dependencies, an extreme gradient boosting (XGBoost) residual corrector to refine forecast errors, and a low-rank adaptation (LoRA)-fine-tuned large language model (LLM) that generates semantic labels of trend direction, anomaly type, and volatility regime to enrich residual learning. Experimental evaluation on real-world cellular traffic data shows up to 15% reduction in root-mean-square error (RMSE) and 10% reduction in mean absolute percentage error (MAPE) compared to state-of-the-art hybrid baselines, with substantially improved resilience to noise, missing data, and abrupt traffic surges. Our contributions include a parameter-efficient prompt-based LoRA fine-tuning pipeline for adapting LLMs to time-series forecasting, a context-aware residual learning architecture fusing numerical and linguistic features, and comprehensive empirical validation demonstrating superior accuracy and robustness in dynamic network environments.", "citations": 0}
{"title": "Large Language Models Encode the Practice of Medicine", "year": 2024, "authors": "Teja Kanchinadam, Shaheen Gauher", "url": "https://www.semanticscholar.org/paper/f66d647bf019b4b126c669bd8511cc997145ddbb", "relevance": 1, "abstract": "Healthcare tasks such as predicting clinical outcomes across medical and surgical populations, disease prediction, predicting patient health journeys, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit super-vision when trained on a new dataset of billions of administrative claims, which essentially encapsulates the practice of medicine, offering a unique perspective on patient care and treatment patterns. Our model, Medi-ClaimGPT, a 125M parameter Transformer demonstrates strong zero-shot predictive capabilities, accurately forecasting patient health events across four evaluation datasets, with its capabilities further demonstrated in various downstream tasks. A significant application of MediClaimGPT is in generating high-quality, clinically plausible synthetic claims data, enhancing healthcare data utility while preserving patient privacy. This research underscores the potential of language models in handling complex datasets and their strategic application in healthcare and related fields.", "citations": 1}
{"title": "ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models", "year": 2025, "authors": "Shixuan Li, Wei Yang, Peiyu Zhang, Xiongye Xiao, De-An Cao, Yuehan Qin, Xiaole Zhang, Yue Zhao, Paul Bogdan", "url": "https://www.semanticscholar.org/paper/4bf24146ff102b640f191da50858f2f08a61d88f", "relevance": 1, "abstract": "Weather forecasting is crucial for public safety, disaster prevention and mitigation, agricultural production, and energy management, with global relevance. Although deep learning has significantly advanced weather prediction, current methods face critical limitations: (i) they often struggle to capture both dynamic temporal dependencies and short-term abrupt changes, making extreme weather modeling difficult; (ii) they incur high computational costs due to extensive training and resource requirements; (iii) they have limited adaptability to multi-scale frequencies, leading to challenges when separating global trends from local fluctuations. To address these issues, we propose ClimateLLM, a foundation model for weather forecasting. It captures spatiotemporal dependencies via a cross-temporal and cross-spatial collaborative modeling framework that integrates Fourier-based frequency decomposition with Large Language Models (LLMs) to strengthen spatial and temporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that adaptively processes different frequency components, enabling efficient handling of both global signals and localized extreme events. In addition, we introduce a cross-temporal and cross-spatial dynamic prompting mechanism, allowing LLMs to incorporate meteorological patterns across multiple scales effectively. Extensive experiments on real-world datasets show that ClimateLLM outperforms state-of-the-art approaches in accuracy and efficiency, as a scalable solution for global weather forecasting.", "citations": 6}
{"title": "Adaptive Frequency-Domain Feature Extraction With Large Language Models for Accurate Electricity Market Forecasting", "year": 2025, "authors": "Qiongbin Chen, Yulin He, Philippe Fournier-Viger, Joshua Zhexue Huang", "url": "https://www.semanticscholar.org/paper/6159a676ad108b32817e59d80e80ed3b7b9ec0c0", "relevance": 1, "abstract": "Time-series forecasting in electricity markets is crucial for ensuring reliable energy supply and stable grid operations. However, traditional time-domain forecasting models encounter significant challenges in capturing the intricate patterns of electricity demand, particularly in multi-frequency data comprising both long-term and short-term dependencies. While frequency-domain analysis is effective at capturing cyclical patterns and short-term fluctuations, existing models struggle to adapt to the dynamic nature of frequency components. Moreover, accurately capturing both global trends and local variations in time-series data remains a persistent challenge. To address these issues, this study introduces a novel adaptive frequency-domain feature extraction model with large language models (AFDFE-LLM) for time-series forecasting. AFDFE-LLM dynamically segments low-, medium-, and high-frequency components, enabling more precise distinction between long-term trends and short-term fluctuations. This approach enhances the adaptability of AFDFE-LLM to respond to the complex and volatile nature of electricity market time-series data. Furthermore, by dynamically optimising frequency-band processing, AFDFE-LLM effectively retains high-frequency details, thus overcoming the information loss typically associated with excessive smoothing in traditional approaches. Experimental results demonstrate that AFDFE-LLM significantly outperforms traditional models, achieving a mean squared error of 0.421 and a mean absolute error of 0.410 on the ETTm1 dataset. The results confirm the robustness and prediction accuracy of the proposed model, particularly in capturing sharp short-term fluctuations and handling complex multi-frequency intertwined data.", "citations": 0}
{"title": "Large Language Models for Predictive Analysis: How Far Are They?", "year": 2025, "authors": "Qin Chen, Yuanyi Ren, Xiaojun Ma, Yuyang Shi", "url": "https://www.semanticscholar.org/paper/5a5139fd00b4443ee0a51e3ed212f137f22542b7", "relevance": 1, "abstract": "Predictive analysis is a cornerstone of modern decision-making, with applications in various domains. Large Language Models (LLMs) have emerged as powerful tools in enabling nuanced, knowledge-intensive conversations, thus aiding in complex decision-making tasks. With the burgeoning expectation to harness LLMs for predictive analysis, there is an urgent need to systematically assess their capability in this domain. However, there is a lack of relevant evaluations in existing studies. To bridge this gap, we introduce the \\textbf{PredictiQ} benchmark, which integrates 1130 sophisticated predictive analysis queries originating from 44 real-world datasets of 8 diverse fields. We design an evaluation protocol considering text analysis, code generation, and their alignment. Twelve renowned LLMs are evaluated, offering insights into their practical use in predictive analysis. Generally, we believe that existing LLMs still face considerable challenges in conducting predictive analysis. See \\href{https://github.com/Cqkkkkkk/PredictiQ}{Github}.", "citations": 3}
{"title": "Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting", "year": 2025, "authors": "Luyao Niu, Zepu Wang, Shuyi Guan, Yang Liu, Peng Sun", "url": "https://www.semanticscholar.org/paper/492ce875b3c5f13cbf27a97d8457294e235aaaab", "relevance": 1, "abstract": "While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.", "citations": 1}
{"title": "ExAnte: A Benchmark for Ex-Ante Inference in Large Language Models", "year": 2025, "authors": "Yachuan Liu, Xiaochun Wei, Lin Shi, Xinnuo Li, Bohan Zhang, Paramveer S. Dhillon, Qiaozhu Mei", "url": "https://www.semanticscholar.org/paper/fd8865e2938d22661d4df3660383e59f07f20b27", "relevance": 1, "abstract": "Large language models (LLMs) face significant challenges in ex-ante reasoning, where analysis, inference, or predictions must be made without access to information from future events. Even with explicit prompts enforcing temporal cutoffs, LLMs often generate outputs influenced by internalized knowledge of events beyond the specified cutoff. This paper introduces a novel task and benchmark designed to evaluate the ability of LLMs to reason while adhering to such temporal constraints. The benchmark includes a variety of tasks: stock prediction, Wikipedia event prediction, scientific publication prediction, and Question Answering (QA), designed to assess factual knowledge under temporal cutoff constraints. We use leakage rate to quantify models' reliance on future information beyond cutoff timestamps. Experimental results reveal that LLMs struggle to consistently adhere to temporal cutoffs across common prompting strategies and tasks, demonstrating persistent challenges in ex-ante reasoning. This benchmark provides a potential evaluation framework to advance the development of LLMs' temporal reasoning ability for time-sensitive applications.", "citations": 0}
{"title": "Deriving Strategic Market Insights with Large Language Models: A Benchmark for Forward Counterfactual Generation", "year": 2025, "authors": "Keane Ong, Rui Mao, Deeksha Varshney, Paul Pu Liang, Erik Cambria, G. Mengaldo", "url": "https://api.semanticscholar.org/CorpusId:278904725", "relevance": 1, "abstract": "Counterfactual reasoning typically involves considering alternatives to actual events. While often applied to understand past events, a distinct form-forward counterfactual reasoning-focuses on anticipating plausible future developments. This type of reasoning is invaluable in dynamic financial markets, where anticipating market developments can powerfully unveil potential risks and opportunities for stakeholders, guiding their decision-making. However, performing this at scale is challenging due to the cognitive demands involved, underscoring the need for automated solutions. LLMs offer promise, but remain unexplored for this application. To address this gap, we introduce a novel benchmark, FIN-FORCE-FINancial FORward Counterfactual Evaluation. By curating financial news headlines and providing structured evaluation, FIN-FORCE supports LLM based forward counterfactual generation. This paves the way for scalable and automated solutions for exploring and anticipating future market developments, thereby providing structured insights for decision-making. Through experiments on FIN-FORCE, we evaluate state-of-the-art LLMs and counterfactual generation methods, analyzing their limitations and proposing insights for future research. We release the benchmark, supplementary data and all experimental codes at the following link: https://github.com/keanepotato/fin_force", "citations": 2}
{"title": "Thermometer: Towards Universal Calibration for Large Language Models", "year": 2024, "authors": "Maohao Shen, Subhro Das, Kristjan H. Greenewald, P. Sattigeri, Greg Wornell, Soumya Ghosh", "url": "https://api.semanticscholar.org/CorpusId:268385471", "relevance": 1, "abstract": "We consider the issue of calibration in large language models (LLM). Recent studies have found that common interventions such as instruction tuning often result in poorly calibrated LLMs. Although calibration is well-explored in traditional applications, calibrating LLMs is uniquely challenging. These challenges stem as much from the severe computational requirements of LLMs as from their versatility, which allows them to be applied to diverse tasks. Addressing these challenges, we propose THERMOMETER, a calibration approach tailored to LLMs. THERMOMETER learns an auxiliary model, given data from multiple tasks, for calibrating a LLM. It is computationally efficient, preserves the accuracy of the LLM, and produces better-calibrated responses for new tasks. Extensive empirical evaluations across various benchmarks demonstrate the effectiveness of the proposed method.", "citations": 25}
{"title": "StreamTS: A Streamline Solution Towards Zero-Shot Time Series Forecasting with Large Language Models", "year": 2025, "authors": "Wei Song, Yi Fang, Xinyu Gu, Wenbo Zhang, Zhixiang Liu, Yu Cheng, Mario Di Mauro", "url": "https://www.semanticscholar.org/paper/5d2e08703233c7c9a33a389617e47a534d497b08", "relevance": 1, "abstract": "Time series forecasting (TSF) is gaining significance in various applications. In recent years, many pre-trained large language models (LLMs) have been proposed, and some of them have been adapted for use in TSF. When applying LLMs to TSF, existing strategies with complex adapters and data preceding modules can increase training time. We introduce StreamTS, a highly streamlined time series forecasting framework built upon LLMs and decomposition-based learning. First, time series are decomposed into a trend component and a seasonal component after instance normalization. Then, a pre-trained LLM facilitated by the proposed BC-Prompt is used for future long-term trend prediction. Concurrently, a linear model simplifies the fitting of future short-term seasonal term. The predicted trend and seasonal series are finally added to generate the forecasting results. In our efforts to achieve zero-shot forecasting, we replace the linear prediction part with a statistical learning method. Extensive experiments demonstrate that our proposed framework outperforms many TSF-specific models across various datasets and achieves significant improvements over LLM-based TSF methods.", "citations": 0}
{"title": "Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?", "year": 2025, "authors": "Yuxuan Zhang, Yangyang Feng, Daifeng Li, Kexin Zhang, Junlan Chen, Bowen Deng", "url": "https://www.semanticscholar.org/paper/07877e5e143655af6e7648a4261f0fb68bb6b91e", "relevance": 1, "abstract": "Multi-agents-based news-driven time series forecasting is considered as a potential paradigm shift in the era of large language models (LLMs). The challenge of this task lies in measuring the influences of different news events towards the fluctuations of time series. This requires agents to possess stronger abilities of innovative thinking and the identifying misleading logic. However, the existing multi-agent discussion framework has limited enhancement on time series prediction in terms of optimizing these two capabilities. Inspired by the role of competition in fostering innovation, this study embeds a competition mechanism within the multi-agent discussion to enhance agents' capability of generating innovative thoughts. Furthermore, to bolster the model's proficiency in identifying misleading information, we incorporate a fine-tuned small-scale LLM model within the reflective stage, offering auxiliary decision-making support. Experimental results confirm that the competition can boost agents' capacity for innovative thinking, which can significantly improve the performances of time series prediction. Similar to the findings of social science, the intensity of competition within this framework can influence the performances of agents, providing a new perspective for studying LLMs-based multi-agent systems.", "citations": 2}
{"title": "Enhancing large language models for bitcoin time series forecasting", "year": 2025, "authors": "O. Chaffard, Pablo Moll\u00e1, Marc Cavazza, Helmut Prendinger", "url": "https://www.semanticscholar.org/paper/a40bbbbe8547575e428463d61be156ce04519fde", "relevance": 1, "abstract": "", "citations": 1}
{"title": "Chronos: Learning the Language of Time Series", "year": 2024, "authors": "Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin Shen, Oleksandr Shchur, Syama Sundar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, Jasper Zschiegner, Danielle C. Maddix, Michael W. Mahoney, Kari Torkkola, Andrew Gordon Wilson, Michael Bohlke-Schneider, Yuyang Wang", "url": "https://www.semanticscholar.org/paper/02fa77e4f355198cb4270f6d4a07517bf09c46dd", "relevance": 1, "abstract": "We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.", "citations": 512}
{"title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting", "year": 2025, "authors": "Jiahao Wang, Mingyue Cheng, Qi Liu", "url": "https://api.semanticscholar.org/CorpusId:279070891", "relevance": 1, "abstract": "Time series forecasting (TSF) is a fundamental and widely studied task, spanning methods from classical statistical approaches to modern deep learning and multimodal language modeling. Despite their effectiveness, these methods often follow a fast thinking paradigm emphasizing pattern extraction and direct value mapping, while overlooking explicit reasoning over temporal dynamics and contextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g., ChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning capabilities across diverse domains, suggesting a new opportunity for reframing TSF as a structured reasoning task. This motivates a key question: can slow-thinking LLMs effectively reason over temporal patterns to support time series forecasting, even in zero-shot manner? To investigate this, in this paper, we propose TimeReasoner, an extensive empirical study that formulates TSF as a conditional reasoning task. We design a series of prompting strategies to elicit inference-time reasoning from pretrained slow-thinking LLMs and evaluate their performance across diverse TSF benchmarks. Our findings reveal that slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities, especially in capturing high-level trends and contextual shifts. While preliminary, our study surfaces important insights into the reasoning behaviors of LLMs in temporal domains highlighting both their potential and limitations. We hope this work catalyzes further research into reasoning-based forecasting paradigms and paves the way toward more interpretable and generalizable TSF frameworks.", "citations": 11}
{"title": "Epidemic Information Extraction for Event-Based Surveillance using Large Language Models", "year": 2024, "authors": "S. Consoli, P. Markov, N. Stilianakis, Lorenzo Bertolini, Antonio Puertas Gallardo, Mario Ceresa", "url": "https://www.semanticscholar.org/paper/2b3f1092201c42f7e91e1daeedf704e119f96aef", "relevance": 1, "abstract": "This paper presents a novel approach to epidemic surveillance, leveraging the power of Artificial Intelligence and Large Language Models (LLMs) for effective interpretation of unstructured big data sources, like the popular ProMED and WHO Disease Outbreak News. We explore several LLMs, evaluating their capabilities in extracting valuable epidemic information. We further enhance the capabilities of the LLMs using in-context learning, and test the performance of an ensemble model incorporating multiple open-source LLMs. The findings indicate that LLMs can significantly enhance the accuracy and timeliness of epidemic modelling and forecasting, offering a promising tool for managing future pandemic events.", "citations": 4}
{"title": "Anticipatory Evaluation of Language Models", "year": 2025, "authors": "Jungsoo Park, Ethan Mendes, Gabriel Stanovsky, Alan Ritter", "url": "https://www.semanticscholar.org/paper/71621c35f531dcec6cb0cd8b88a2e5b538d5294e", "relevance": 1, "abstract": "Progress in large language models is increasingly constrained by an evaluation bottleneck: benchmarks must be built and models run before iteration can begin. We investigate whether evaluation outcomes can be forecast before any experiments are conducted. Specifically, we study text-only performance prediction, where models estimate performance from task descriptions and experimental configurations alone, without access to dataset instances. To support systematic study, we curate PRECOG, a corpus of description-performance pairs spanning diverse tasks, domains, and metrics. We scrape task and configuration descriptions from arXiv, yielding 2,290 instances covering 1,519 papers, and construct a test split using papers published after the evaluated models'knowledge cutoff. Experiments show the task is challenging but feasible: reasoning models achieve a non-trivial forecasting skill reaching mean absolute error as low as 9.9 at high-confidence thresholds. Overall, our corpus and analyses offer an initial step toward open-ended anticipatory evaluation, supporting difficulty estimation and smarter resource allocation.", "citations": 0}
{"title": "FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets", "year": 2023, "authors": "Neng Wang, Hongyang Yang, Chris Wang", "url": "https://www.semanticscholar.org/paper/bd09391fbd124dc0c0a6be5d0ab2eb5d9c43fbac", "relevance": 1, "abstract": "In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for open-source large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, we delve into a comprehensive model, executing multi-task operations by amalgamating all instructional tunings to examine versatility. Finally, we explore the zero-shot capabilities by earmarking unseen tasks and incorporating novel datasets to understand adaptability in uncharted terrains. Such a paradigm fortifies the principles of openness and reproducibility, laying a robust foundation for future investigations in open-source financial large language models (FinLLMs).", "citations": 95}
{"title": "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series", "year": 2023, "authors": "Chenxi Sun, Yaliang Li, Hongyan Li, linda Qiao", "url": "https://www.semanticscholar.org/paper/d84cf745c534c010b8e55e5a4a04878906848dc3", "relevance": 1, "abstract": "This work summarizes two ways to accomplish Time-Series (TS) tasks in today's Large Language Model (LLM) context: LLM-for-TS (model-centric) designs and trains a fundamental large model, or fine-tunes a pre-trained LLM for TS data; TS-for-LLM (data-centric) converts TS into a model-friendly representation to enable the pre-trained LLM to handle TS data. Given the lack of data, limited resources, semantic context requirements, and so on, this work focuses on TS-for-LLM, where we aim to activate LLM's ability for TS data by designing a TS embedding method suitable for LLM. The proposed method is named TEST. It first tokenizes TS, builds an encoder to embed TS via instance-wise, feature-wise, and text-prototype-aligned contrast, where the TS embedding space is aligned to LLM embedding layer space, then creates soft prompts to make LLM more open to that embeddings, and finally implements TS tasks using the frozen LLM. We also demonstrate the feasibility of TS-for-LLM through theory and experiments. Experiments are carried out on TS classification, forecasting, and representation tasks using eight frozen LLMs with various structures and sizes. The results show that the pre-trained LLM with TEST strategy can achieve better or comparable performance than today's SOTA TS models and offer benefits for few-shot and generalization. By treating LLM as the pattern machine, TEST can endow LLM's ability to process TS data without compromising language ability. We hope that this study will serve as a foundation for future work to support TS+LLM progress.", "citations": 198}
{"title": "Sparse Attention Combined with RAG Technology for Financial Data Analysis", "year": 2025, "authors": "Zhaoyan Zhang, Kaixian Xu, Yu Qiao, Alan Wilson", "url": "https://api.semanticscholar.org/CorpusId:277372776", "relevance": 1, "abstract": "In response to the challenges of multimodal data integration, real-time information retrieval, model hallucination, and lack of interpretability in financial stock analysis, this paper proposes an innovative financial analysis framework\u2014FSframe. It aims to address multiple challenges in stock analysis within the financial sector. The framework integrates various technological modules to provide comprehensive and efficient solutions for stock trend prediction and financial question answering tasks. First, FSframe optimizes large language models (LLMs), enhancing their adaptability to financial tasks, and incorporates prompt engineering to mitigate potential hallucination issues during the generation process, thereby improving the accuracy and reliability of the analysis. Secondly, the framework introduces Retrieval-Augmented Generation (RAG) technology, creating a dynamically updated financial knowledge base that enables the model to retrieve and integrate the latest market data, providing real-time external knowledge support for tasks. Furthermore, FSframe adopts a sparse attention mechanism, optimizing the processing efficiency of time-series data by filtering irrelevant information and focusing on key points, while also achieving efficient integration of time-series and textual data. Finally, through its modular design, FSframe organically combines the aforementioned advanced technologies, forming an innovative solution that blends multimodal data processing with real-time analysis, offering strong technical support for intelligent analysis in the financial sector. Validation on large-scale financial datasets (including historical stock prices, financial news, and market announcements) shows that FSframe significantly improves prediction accuracy and real-time responsiveness in stock trend forecasting and financial question answering tasks. Experimental results indicate that FSframe offers significant advantages in multimodal data integration, real-time performance, and interpretability, demonstrating excellent task adaptability and addressing the shortcomings of traditional methods. The FSframe framework not only provides an innovative solution for stock analysis in the financial sector but also opens new pathways for the development of intelligent financial technologies.", "citations": 1}
{"title": "A Brief Survey on Temporal Reasoning Based on Large Language Models", "year": 2024, "authors": "Panfeng Zhang, Huan Zhang, Xiaoke Wang, Fu Zhang, Fan Yu", "url": "https://www.semanticscholar.org/paper/3847ba79180381061715d8100ee37eea9652e1d0", "relevance": 1, "abstract": "Temporal reasoning is a pivotal mechanism for understanding the world around us, enabling inference, prediction, and deduction of temporal relationships among events. The advent of Large Language Models (LLMs) has sparked considerable interest in research on temporal reasoning utilizing these models. These models, trained on massive datasets, acquire potent representational capabilities, allowing them to learn temporal patterns and perform inference and prediction on complex temporal data. We provide a brief overview of recent research on temporal reasoning based on LLMs, exploring the capabilities of LLMs in temporal reasoning and outlining future directions. We particularly focus on four major research areas: Time Series Forecasting, Temporal Question Answering, Temporal Knowledge Graph and Assessing Temporal Reasoning Capability in LLMs. Through this review, we aim to offer new insights and perspectives for research and applications in the field of temporal reasoning, further advancing research on LLMs in temporal reasoning.", "citations": 0}
{"title": "MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction", "year": 2024, "authors": "Mengyu Wang, Tiejun Ma", "url": "https://api.semanticscholar.org/CorpusId:272525374", "relevance": 1, "abstract": "It is widely acknowledged that extracting market sentiments from news data benefits market predictions. However, existing methods of using financial sentiments remain simplistic, relying on equal-weight and static aggregation to manage sentiments from multiple news items. This leads to a critical issue termed \"Aggregated Sentiment Homogenization'', which has been explored through our analysis of a large financial news dataset from industry practice. This phenomenon occurs when aggregating numerous sentiments, causing representations to converge towards the mean values of sentiment distributions and thereby smoothing out unique and important information. Consequently, the aggregated sentiment representations lose much predictive value of news data. To address this problem, we introduce the Market Attention-weighted News Aggregation Network (MANA-Net), a novel method that leverages a dynamic market-news attention mechanism to aggregate news sentiments for market prediction. MANA-Net learns the relevance of news sentiments to price changes and assigns varying weights to individual news items. By integrating the news aggregation step into the networks for market prediction, MANA-Net allows for trainable sentiment representations that are optimized directly for prediction. We evaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with financial news spanning from 2003 to 2018. Experimental results demonstrate that MANA-Net outperforms various recent market prediction methods, enhancing Profit & Loss by 1.1% and the daily Sharpe ratio by 0.252.", "citations": 7}
{"title": "Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?", "year": 2024, "authors": "Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks", "url": "https://api.semanticscholar.org/CorpusId:271571299", "relevance": 1, "abstract": "As artificial intelligence systems grow more powerful, there has been increasing interest in\"AI safety\"research to address emerging and future risks. However, the field of AI safety remains poorly defined and inconsistently measured, leading to confusion about how researchers can contribute. This lack of clarity is compounded by the unclear relationship between AI safety benchmarks and upstream general capabilities (e.g., general knowledge and reasoning). To address these issues, we conduct a comprehensive meta-analysis of AI safety benchmarks, empirically analyzing their correlation with general capabilities across dozens of models and providing a survey of existing directions in AI safety. Our findings reveal that many safety benchmarks highly correlate with both upstream model capabilities and training compute, potentially enabling\"safetywashing\"--where capability improvements are misrepresented as safety advancements. Based on these findings, we propose an empirical foundation for developing more meaningful safety metrics and define AI safety in a machine learning research context as a set of clearly delineated research goals that are empirically separable from generic capabilities advancements. In doing so, we aim to provide a more rigorous framework for AI safety research, advancing the science of safety evaluations and clarifying the path towards measurable progress.", "citations": 48}
{"title": "Interpretable glucose forecasting for type 2 diabetes across traditional, deep, and large language models", "year": 2025, "authors": "Rawan Alredaini, M. Abulkhair, Hind Almisbahi", "url": "https://www.semanticscholar.org/paper/dcfa2e2cc3260aa02d6594f8c463efc3e755e78c", "relevance": 1, "abstract": "Type 2 diabetes mellitus (T2DM) is a prevalent chronic condition characterized by elevated blood glucose levels resulting from insulin resistance or inadequate insulin secretion. Accurate prediction of future glucose levels is essential for minimizing complications and enabling proactive management. While machine learning and deep learning models have been extensively applied in this domain, the potential of large language models (LLMs) remains underexplored, with no prior studies systematically comparing them to conventional approaches using real patient data. In this study, we evaluate three model types: traditional (XGBoost, Random Forest), deep learning (GRU, LSTM, Transformer, Ensemble), and finetuned LLMs (GPT-4.1, MiniGPT, LLaMA-1B, LLaMA-7B), for predicting glucose levels 30, 60, and 90 minutes ahead using hybrid inputs of six static features and 20 prior CGM readings. GPT-4.1 achieved the best performance at 30 and 60 minutes, while LLaMA-7B excelled at 90 minutes. Among conventional models, LSTM showed the best performance. Beyond forecasting, interpretability was a central focus. We used explainable AI (XAI) techniques to interpret LSTM results, while GPT-4.1 explained its predictions directly using natural language, without additional training. Notably, the study revealed an alignment between the two explanation techniques, with both highlighting recent glucose readings as key predictors across all forecasting horizons.", "citations": 0}
{"title": "From Simulation to Prediction: Enhancing Digital Twins with Advanced Generative AI Technologies", "year": 2024, "authors": "Yijun Huang, Jihan Zhang, Xi Chen, Alan H. F. Lam, Ben M. Chen", "url": "https://www.semanticscholar.org/paper/206d97a41e97000839bb3ee9c1b22541d1bc147c", "relevance": 1, "abstract": "The integration of Generative Artificial Intelli-gence (GAI) into Digital Twins (DTs) marks a revolutionary stride in the evolution of virtual replicas for physical systems. This paper explores the cutting-edge advancements brought about by the incorporation of GAI technologies, specifically Large Language Models (LLMs), into DTs. These technologies herald a significant transformation, propelling DTs beyond their current capabilities to become more dynamic, predictive, and interactive tools that can simulate complex scenarios and anticipate future conditions with remarkable accuracy. By systematically examining the levels of GAI integration within DTs, this study delves into the methodologies and strategies for embedding AI capabilities into these virtual models. It outlines how GAI can enhance the functionality of DTs, enabling them to generate synthetic datasets, simulate unprecedented events, and provide actionable insights with LLM-based agents for decision-making. Furthermore, the paper highlights the extended applications of DTs, enriched by GAI, across various domains such as healthcare, urban planning, and beyond. The implications of this integration for operational efficiency, innovation, and decision-making processes are profound. By offering a comprehensive overview of the current state of technology and projecting future trends, this paper aims to provide stakeholders with a deep understanding of the syner-gistic potential between GAI and DTs. It sets the stage for a new era of DT technologies, where the boundaries of what can be achieved with virtual models are continually expanding.", "citations": 12}
{"title": "TimeCMA: Towards LLM-Empowered Time Series Forecasting via Cross-Modality Alignment", "year": 2024, "authors": "Chenxi Liu, Qianxiong Xu, Hao Miao, Sun Yang, Lingzheng Zhang, Cheng Long, Ziyue Li, Rui Zhao", "url": "https://www.semanticscholar.org/paper/6d4adaecfc639d190d1b2a8cc25f9cdd0fac8aaf", "relevance": 1, "abstract": "", "citations": 37}
{"title": "LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law", "year": 2024, "authors": "Toni J. B. Liu, Nicolas Boulle, Raphael Sarfati, C. Earls", "url": "https://www.semanticscholar.org/paper/93b058243165c2b2e06c6802ab12538713e167c3", "relevance": 1, "abstract": "We study LLMs\u2019 ability to extrapolate the behavior of various dynamical systems, including stochastic, chaotic, continuous, and discrete systems, whose evolution is governed by principles of physical interest. Our results show that LLaMA-2, a language model trained on text, achieves accurate predictions of dynamical system time series without fine-tuning or prompt engineering. Moreover, the accuracy of the learned physical rules increases with the length of the input context window, revealing an in-context version of a neural scaling law. Along the way, we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from LLMs.", "citations": 33}
{"title": "FinPT: Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models", "year": 2023, "authors": "Yuwei Yin, Yazheng Yang, Jian Yang, Jian Yang, Qi Liu", "url": "https://www.semanticscholar.org/paper/f6f91a650b59d8f4e7f8924dafc98c8a2058c422", "relevance": 1, "abstract": "Financial risk prediction plays a crucial role in the financial sector. Machine learning methods have been widely applied for automatically detecting potential risks and thus saving the cost of labor. However, the development in this field is lagging behind in recent years by the following two facts: 1) the algorithms used are somewhat outdated, especially in the context of the fast advance of generative AI and large language models (LLMs); 2) the lack of a unified and open-sourced financial benchmark has impeded the related research for years. To tackle these issues, we propose FinPT and FinBench: the former is a novel approach for financial risk prediction that conduct Profile Tuning on large pretrained foundation models, and the latter is a set of high-quality datasets on financial risks such as default, fraud, and churn. In FinPT, we fill the financial tabular data into the pre-defined instruction template, obtain natural-language customer profiles by prompting LLMs, and fine-tune large foundation models with the profile text to make predictions. We demonstrate the effectiveness of the proposed FinPT by experimenting with a range of representative strong baselines on FinBench. The analytical studies further deepen the understanding of LLMs for financial risk prediction.", "citations": 23}
{"title": "S2IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting", "year": 2024, "authors": "Zijie Pan, Yushan Jiang, Sahil Garg, Anderson Schneider, Yuriy Nevmyvaka, Dongjin Song", "url": "https://www.semanticscholar.org/paper/a0e7f328781eda3e3dc919c77bd1eedb99b99612", "relevance": 1, "abstract": "Recently, there has been a growing interest in leveraging pre-trained large language models (LLMs) for various time series applications. However, the semantic space of LLMs, established through the pre-training, is still underexplored and may help yield more distinctive and informative representations to facilitate time series forecasting. To this end, we propose Semantic Space Informed Prompt learning with LLM ($S^2$IP-LLM) to align the pre-trained semantic space with time series embeddings space and perform time series forecasting based on learned prompts from the joint space. We first design a tokenization module tailored for cross-modality alignment, which explicitly concatenates patches of decomposed time series components to create embeddings that effectively encode the temporal dynamics. Next, we leverage the pre-trained word token embeddings to derive semantic anchors and align selected anchors with time series embeddings by maximizing the cosine similarity in the joint space. This way, $S^2$IP-LLM can retrieve relevant semantic anchors as prompts to provide strong indicators (context) for time series that exhibit different temporal dynamics. With thorough empirical studies on multiple benchmark datasets, we demonstrate that the proposed $S^2$IP-LLM can achieve superior forecasting performance over state-of-the-art baselines. Furthermore, our ablation studies and visualizations verify the necessity of prompt learning informed by semantic space.", "citations": 16}
{"title": "LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization", "year": 2025, "authors": "Bangyu Li, Boping Gu, Ziyang Ding", "url": "https://www.semanticscholar.org/paper/46f44f59446fbf7baa29c190fa95adc83a2a4c9f", "relevance": 1, "abstract": "In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender , an integrated framework that combines Large Language Models, reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making.", "citations": 0}
{"title": "Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned Financial Asset Recommendations", "year": 2025, "authors": "Fernando Spadea, O. Seneviratne", "url": "https://www.semanticscholar.org/paper/8d6552a105be40d7e33262b71ac7e67550f720c8", "relevance": 1, "abstract": "Large language models (LLMs) show promise for personalized financial recommendations but are hampered by context limits, hallucinations, and a lack of behavioral grounding. Our prior work, FLARKO, embedded structured knowledge graphs (KGs) in LLM prompts to align advice with user behavior and market data. This paper introduces RAG-FLARKO, a retrieval-augmented extension to FLARKO, that overcomes scalability and relevance challenges using multi-stage and parallel KG retrieval processes. Our method first retrieves behaviorally relevant entities from a user's transaction KG and then uses this context to filter temporally consistent signals from a market KG, constructing a compact, grounded subgraph for the LLM. This pipeline reduces context overhead and sharpens the model's focus on relevant information. Empirical evaluation on a real-world financial transaction dataset demonstrates that RAG-FLARKO significantly enhances recommendation quality. Notably, our framework enables smaller, more efficient models to achieve high performance in both profitability and behavioral alignment, presenting a viable path for deploying grounded financial AI in resource-constrained environments.", "citations": 0}
{"title": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models", "year": 2025, "authors": "Ching Chang, Yidan Shi, Defu Cao, Wei Yang, Jeehyun Hwang, Haixin Wang, Jiacheng Pang, Wei Wang, Yan Liu, Wen-Chih Peng, Tien-Fu Chen", "url": "https://www.semanticscholar.org/paper/127ab36cee7c8c1b5e7ec4a8cd40963402803825", "relevance": 1, "abstract": "Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey). Evaluation practices that keep evidence visible and temporally aligned are highlighted, and guidance is distilled on matching topology to uncertainty, grounding with observable artifacts, planning for shift and streaming, and treating cost and latency as design budgets. We emphasize that reasoning structures must balance capacity for grounding and self-correction against computational cost and reproducibility, while future progress will likely depend on benchmarks that tie reasoning quality to utility and on closed-loop testbeds that trade off cost and risk under shift-aware, streaming, and long-horizon settings. Taken together, these directions mark a shift from narrow accuracy toward reliability at scale, enabling systems that not only analyze but also understand, explain, and act on dynamic worlds with traceable evidence and credible outcomes.", "citations": 6}
{"title": "Predicting Empirical AI Research Outcomes with Language Models", "year": 2025, "authors": "Jiaxin Wen, Chenglei Si, Yueh-han Chen, He He, Shi Feng", "url": "https://www.semanticscholar.org/paper/9ee4e183e5d710a561b17ff1c157fbf34c97c1a5", "relevance": 1, "abstract": "Many promising-looking ideas in AI research fail to deliver, but their validation takes substantial human labor and compute. Predicting an idea's chance of success is thus crucial for accelerating empirical AI research, a skill that even expert researchers can only acquire through substantial experience. We build the first benchmark for this task and compare LMs with human experts. Concretely, given two research ideas (e.g., two jailbreaking methods), we aim to predict which will perform better on a set of benchmarks. We scrape ideas and experimental results from conference papers, yielding 1,585 human-verified idea pairs published after our base model's cut-off date for testing, and 6,000 pairs for training. We then develop a system that combines a fine-tuned GPT-4.1 with a paper retrieval agent, and we recruit 25 human experts to compare with. In the NLP domain, our system beats human experts by a large margin (64.4% v.s. 48.9%). On the full test set, our system achieves 77% accuracy, while off-the-shelf frontier LMs like o3 perform no better than random guessing, even with the same retrieval augmentation. We verify that our system does not exploit superficial features like idea complexity through extensive human-written and LM-designed robustness tests. Finally, we evaluate our system on unpublished novel ideas, including ideas generated by an AI ideation agent. Our system achieves 63.6% accuracy, demonstrating its potential as a reward model for improving idea generation models. Altogether, our results outline a promising new direction for LMs to accelerate empirical AI research.", "citations": 5}
{"title": "AI can outperform humans in predicting correlations between personality items", "year": 2025, "authors": "P. Schoenegger, Spencer Greenberg, Alexander Grishin, Joshua Lewis, Lucius Caviola", "url": "https://www.semanticscholar.org/paper/cbfc008c08cbb9354b04f86a71e37b1cb284c15b", "relevance": 1, "abstract": "We assess the abilities of both specialized deep neural networks, such as PersonalityMap, and general LLMs, including GPT-4o and Claude 3 Opus, in understanding human personality by predicting correlations between personality questionnaire items. All AI models outperform the vast majority of laypeople and academic experts. However, we can improve the accuracy of individual correlation predictions by taking the median prediction per group to produce a \u201cwisdom of the crowds\u201d estimate. Thus, we also compare the median predictions from laypeople, academic experts, GPT-4o/Claude 3 Opus, and PersonalityMap. Based on medians, PersonalityMap and academic experts surpass both LLMs and laypeople on most measures. These results suggest that while advanced LLMs make superior predictions compared to most individual humans, specialized models like PersonalityMap can match even expert group-level performance in domain-specific tasks. This underscores the capabilities of large language models while emphasizing the continued relevance of specialized systems as well as human experts for personality research. Specialized neural networks and general large language models outperform individual humans at predicting personality questionnaire item correlations, but specialized models and aggregated expert predictions achieve the highest accuracy on most measures.", "citations": 4}
{"title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling", "year": 2026, "authors": "Panagiotis Lymperopoulos, Abhiramon Rajasekharan, Ian Berlot-Attwell, St'ephane Aroca-Ouellette, Kaheer Suleman", "url": "https://www.semanticscholar.org/paper/287cdf4ef9f5d4c02e1ccc82f542f92edaefb868", "relevance": 1, "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.", "citations": 0}
{"title": "Detecting Future-related Contexts of Entity Mentions", "year": 2025, "authors": "Puneet Prashar, Krishna Mohan Shukla, Adam Jatowt", "url": "https://www.semanticscholar.org/paper/12d5515579a8334246acfc152a4d740d048d9f30", "relevance": 1, "abstract": "The ability to automatically identify whether an entity is referenced in a future context can have multiple applications including decision making, planning and trend forecasting. This paper focuses on detecting implicit future references in entity-centric texts, addressing the growing need for automated temporal analysis in information processing. We first present a novel dataset of 19,540 sentences built around popular entities sourced from Wikipedia, which consists of future-related and non-future-related contexts in which those entities appear. As a second contribution, we evaluate the performance of several Language Models including also Large Language Models (LLMs) on the task of distinguishing future-oriented content in the absence of explicit temporal references.", "citations": 1}
{"title": "On Identifying Why and When Foundation Models Perform Well on Time-Series Forecasting Using Automated Explanations and Rating", "year": 2025, "authors": "Michael Widener, Kausik Lakkaraju, John Aydin, Biplav Srivastava", "url": "https://www.semanticscholar.org/paper/a44ebbb00935239b53b46d334725e7a917c31afc", "relevance": 1, "abstract": "Time-series forecasting models (TSFM) have evolved from classical statistical methods to sophisticated foundation models, yet understanding why and when these models succeed or fail remains challenging. Despite this known limitation, time-series forecasting models are increasingly used to generate\ninformation that informs real-world actions with equally real consequences. Understanding the complexity, performance variability, and opaque nature of these models then becomes a valuable endeavor to combat serious concerns about how users should interact with and rely on these models\u2019 outputs. This work addresses these concerns by combining traditional explainable AI (XAI) methods with Rating Driven Explanations (RDE) to assess TSFM performance and interpretability across diverse domains and use cases. We evaluate four distinct model architectures: ARIMA, Gradient Boosting, Chronos (time-series specific foundation model), Llama (general-purpose; both fine-tuned and base models) on four heterogeneous datasets spanning finance, energy, transportation, and automotive sales domains. In doing so, we\ndemonstrate that feature-engineered models (e.g., Gradient Boosting) consistently outperform foundation models (e.g., Chronos) in volatile or sparse domains (e.g., power, car parts) while providing more interpretable explanations, whereas foundation models excel only in stable or trend-driven contexts (e.g., finance).", "citations": 0}
{"title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "year": 2025, "authors": "Junqiao Wang, Zhaoyang Guan, Guanyu Liu, Tianze Xia, Xianzhi Li, Shuo Yin, Xinyuan Song, Chuhan Cheng, Tianyu Shi, Alex Lee", "url": "https://www.semanticscholar.org/paper/04c9b4d253ac3f2fd3d2b60ca25b485922e94a82", "relevance": 1, "abstract": "Predicting cryptocurrency returns is notoriously difficult: price movements are driven by a fast-shifting blend of on-chain activity, news flow, and social sentiment, while labeled training data are scarce and expensive. In this paper, we present Meta-RL-Crypto, a unified transformer-based architecture that unifies meta-learning and reinforcement learning (RL) to create a fully self-improving trading agent. Starting from a vanilla instruction-tuned LLM, the agent iteratively alternates between three roles-actor, judge, and meta-judge-in a closed-loop architecture. This learning process requires no additional human supervision. It can leverage multimodal market inputs and internal preference feedback. The agent in the system continuously refines both the trading policy and evaluation criteria. Experiments across diverse market regimes demonstrate that Meta-RL-Crypto shows good performance on the technical indicators of the real market and outperforming other LLM-based baselines.", "citations": 0}
{"title": "The role of AI recommendations in extending\u00a0the\u00a0Black-Litterman portfolio", "year": 2025, "authors": "S. Hoang, S. Dey, Tho Huu-Hoang Nguyen, Phuong Ngoc Duy Nguyen", "url": "https://www.semanticscholar.org/paper/93899102a159389def0683ddf8af593bf8092cb4", "relevance": 1, "abstract": "\n \n This study explores the role of artificial intelligence (AI) recommendations in portfolio optimization by extending the Black-Litterman (BL) model using consensus analyst opinions generated by ChatGPT. The aim is to assess if AI recommendations can improve portfolio diversification and risk-adjusted returns compared to traditional investment strategies.\n \n \n \n We conducted a quantitative analysis using weekly historical price data across equities, commodities, fixed-income securities and cryptocurrencies from January 2018 to May 2023. Portfolios constructed with the extended BL model were tested against standard benchmarks, including the S&P500 index and various mean-variance portfolios. Out-of-sample performance and robustness were evaluated through 100 random resampling procedures.\n \n \n \n Results indicate that integrating AI-generated analyst consensus significantly improves the BL portfolio\u2019s risk-adjusted returns. The AI-enhanced model consistently outperformed traditional mean-variance portfolios, the unadjusted BL model and market benchmarks. Robustness tests confirmed the method\u2019s stability and practical feasibility in real-world investing.\n \n \n \n Portfolio managers and individual investors can apply this enhanced BL model for more effective asset\u00a0allocation decisions. Using AI-generated recommendations simplifies the integration of broad analyst perspectives, reduces reliance on subjective human judgments and leads to portfolios that deliver stronger and more consistent risk-adjusted performance.\n \n \n \n This research is the first to integrate ChatGPT-generated analyst recommendations directly into the BL framework. It addresses critical limitations of modern portfolio theory, particularly estimation errors, offering a practical solution leveraging AI advancements for portfolio optimization.\n", "citations": 0}
{"title": "Using Transformers and Deep Learning with Stance Detection to Forecast Cryptocurrency Price Movement", "year": 2022, "authors": "Yeonwoo Son, Soham Vohra, Rohit Vakkalagadda, Michael Zhu, Aadvait Hirde, Saurav Kumar, Arjun Rajaram", "url": "https://www.semanticscholar.org/paper/aafafa3527f49a73b8575dd5115859cac0687182", "relevance": 1, "abstract": "The volatility of cryptocurrencies and exclusivity of crypto communities has made cryptocurrency investment inaccessible for common people. With machine learning, harnessing social media trends that affect price in a random field like cryptocurrency will provide everybody the ability to earn money. Although existing research utilizes sentiment analysis to label posts based solely on English, this project will use NLP to perform stance detection with respect to a certain entity to make predictions. The second part of this project will apply this stance detection to real-world prices, using an RNN to turn stance data into price data. The stance detection model, RoBERTa, reached an accuracy of 80%. An independent price prediction model using an RNN achieved a mean absolute error of $1144, a relatively minimal error considering that the price of crypto reaches $60000. This endeavor proves the difficulty in proving cryptocurrency prices, but the model's steady improvement indicates that future work on social media trends may be promising after all.", "citations": 7}
{"title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity", "year": 2023, "authors": "Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie, Zheng Zhang, Yue Zhang", "url": "https://api.semanticscholar.org/CorpusId:263835211", "relevance": 1, "abstract": "This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.", "citations": 266}
{"title": "I NFORMED F ORECASTING : L EVERAGING A UXILIARY K NOWLEDGE TO B OOST L ARGE L ANGUAGE M ODELS P ERFORMANCE ON T IME S ERIES F ORECASTING", "year": null, "authors": "Mohammadmahdi Ghasemloo, Alireza Moradi", "url": "https://www.semanticscholar.org/paper/3bba1fd7ed05bc91067b90fa21a40218ce100f20", "relevance": 1, "abstract": "", "citations": 0}
{"title": "Cross-Sector Market Regime Forecasting with LLM-Augmented News Analysis", "year": 2024, "authors": "Timur Mudarisov, Radu State, Zsofia Kraussl, Alexander Yakubov, Tatiana Petrova", "url": "https://api.semanticscholar.org/CorpusId:274077492", "relevance": 1, "abstract": "This paper investigates the utilization of news in predicting market regimes. The findings illustrate that employing an ensemble of multiple FinBERT models can outperform straightforward time-series prediction by 73% in accuracy and 110% in F1 score. The NLP models demonstrate strong performance across two different market-regime scenarios and show the ability to detect market shifts.", "citations": 1}
{"title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "year": 2025, "authors": "Quan Li, Wenchao Yu, Suhang Wang, Min Lin, Lingwei Chen, Wei Cheng, Haifeng Chen", "url": "https://api.semanticscholar.org/CorpusId:282304275", "relevance": 1, "abstract": "Extreme events frequently occur in real-world time series and often carry significant practical implications. In domains such as climate and healthcare, these events, such as floods, heatwaves, or acute medical episodes, can lead to serious consequences. Accurate forecasting of such events is therefore of substantial importance. Most existing time series forecasting models are optimized for overall performance within the prediction window, but often struggle to accurately predict extreme events, such as high temperatures or heart rate spikes. The main challenges are data imbalance and the neglect of valuable information contained in intermediate events that precede extreme events. In this paper, we propose xTime, a novel framework for extreme event forecasting in time series. xTime leverages knowledge distillation to transfer information from models trained on lower-rarity events, thereby improving prediction performance on rarer ones. In addition, we introduce a mixture of experts (MoE) mechanism that dynamically selects and fuses outputs from expert models across different rarity levels, which further improves the forecasting performance for extreme events. Experiments on multiple datasets show that xTime achieves consistent improvements, with forecasting accuracy on extreme events improving from 3% to 78%.", "citations": 0}
{"title": "A decoder-only foundation model for time-series forecasting", "year": 2023, "authors": "Abhimanyu Das, Weihao Kong, Rajat Sen, Yichen Zhou", "url": "https://api.semanticscholar.org/CorpusId:264172792", "relevance": 1, "abstract": "Motivated by recent advances in large language models for Natural Language Processing (NLP), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset. Our model is based on pretraining a patched-decoder style attention model on a large time-series corpus, and can work well across different forecasting history lengths, prediction lengths and temporal granularities.", "citations": 485}
{"title": "Hybrid forecasting of geopolitical events\u2020", "year": 2023, "authors": "Daniel M. Benjamin, Fred Morstatter, A. Abbas, Andr\u00e9s Abeliuk, Pavel Atanasov, Stephen T. Bennett, Andreas Beger, Saurabh Birari, D. Budescu, Michele Catasta, Emilio Ferrara, Lucas Haravitch, Mark Himmelstein, K. T. Hossain, Yuzhong Huang, Woojeong Jin, R. Joseph, J. Leskovec, Akira Matsui, Mehrnoosh Mirtaheri, Xiang Ren, Gleb Satyukov, Rajiv Sethi, Amandeep Singh, R. Sosi\u010d, M. Steyvers, Pedro A. Szekely, M. D. Ward, A. Galstyan", "url": "https://www.semanticscholar.org/paper/b5aad38122c14f4287c5feca20b7017fda50d7c0", "relevance": 1, "abstract": "Sound decision-making relies on accurate prediction for tangible outcomes ranging from military conflict to disease outbreaks. To improve crowdsourced forecasting accuracy, we developed SAGE, a hybrid forecasting system that combines human and machine generated forecasts. The system provides a platform where users can interact with machine models and thus anchor their judgments on an objective benchmark. The system also aggregates human and machine forecasts weighting both for propinquity and based on assessed skill while adjusting for overconfidence. We present results from the Hybrid Forecasting Competition (HFC) - larger than comparable forecasting tournaments - including 1085 users forecasting 398 real-world forecasting problems over eight months. Our main result is that the hybrid system generated more accurate forecasts compared to a human-only baseline which had no machine generated predictions. We found that skilled forecasters who had access to machine-generated forecasts outperformed those who only viewed historical data. We also demonstrated the inclusion of machine-generated forecasts in our aggregation algorithms improved performance, both in terms of accuracy and scalability. This suggests that hybrid forecasting systems, which potentially require fewer human resources, can be a viable approach for maintaining a competitive level of accuracy over a larger number of forecasting questions.", "citations": 17}
{"title": "A systematic review for transformer-based long-term series forecasting", "year": 2023, "authors": "Liyilei Su, Xumin Zuo, Rui Li, Xin Wang, Heng Zhao, Bingding Huang", "url": "https://api.semanticscholar.org/CorpusId:264814099", "relevance": 1, "abstract": "The emergence of deep learning has yielded noteworthy advancements in time series forecasting (TSF). Transformer architectures have witnessed broad utilization and adoption in TSF tasks. Transformers have proven to be the most successful solution to extract the semantic correlations among the elements within a long sequence. Various variants have enabled Transformer architecture to effectively handle long-term time series forecasting (LTSF) tasks. In this article, we first present a comprehensive overview of Transformer architectures and their subsequent enhancements developed to address various LTSF tasks. Then, we summarize the publicly available LTSF datasets and relevant evaluation metrics. Furthermore, we provide valuable insights into the best practices and techniques for effectively training Transformers in the context of time-series analysis. Lastly, we propose potential research directions in this rapidly evolving field.", "citations": 88}
{"title": "History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting", "year": 2025, "authors": "Sarthak Khanna, Armin Berger, M. Chopra, David Berghaus, R. Sifa", "url": "https://www.semanticscholar.org/paper/c138487d485d54d3135e25c0a35a8b52e945b889", "relevance": 1, "abstract": "Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining. Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that\"financial history may not repeat, but it often rhymes,\"this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change. All datasets, models, and source code are publicly available.", "citations": 0}
{"title": "Foundation Time-Series AI Model for Realized Volatility Forecasting", "year": 2025, "authors": "Anubha Goel, P. Pasricha, M. Magris, J. Kanniainen", "url": "https://api.semanticscholar.org/CorpusId:278715132", "relevance": 1, "abstract": "Time series foundation models (FMs) have emerged as a popular paradigm for zero-shot multi-domain forecasting. These models are trained on numerous diverse datasets and claim to be effective forecasters across multiple different time series domains, including financial data. In this study, we evaluate the effectiveness of FMs, specifically the TimesFM model, for volatility forecasting, a core task in financial risk management. We first evaluate TimesFM in its pretrained (zero-shot) form, followed by our custom fine-tuning procedure based on incremental learning, and compare the resulting models against standard econometric benchmarks. While the pretrained model provides a reasonable baseline, our findings show that incremental fine-tuning, which allows the model to adapt to new financial return data over time, is essential for learning volatility patterns effectively. Fine-tuned variants not only improve forecast accuracy but also statistically outperform traditional models, as demonstrated through Diebold-Mariano and Giacomini-White tests. These results highlight the potential of foundation models as scalable and adaptive tools for financial forecasting-capable of delivering strong performance in dynamic market environments when paired with targeted fine-tuning strategies.", "citations": 3}
{"title": "Future Language Modeling from Temporal Document History", "year": 2024, "authors": "Changmao Li, Jeffrey Flanigan", "url": "https://api.semanticscholar.org/CorpusId:269157281", "relevance": 1, "abstract": "Predicting the future is of great interest across many aspects of human activity. Businesses are interested in future trends, traders are interested in future stock prices, and companies are highly interested in future technological breakthroughs. While there are many automated systems for predicting future numerical data, such as weather, stock prices, and demand for products, there is relatively little work in automatically predicting textual data. Humans are interested in textual data predictions because it is a natural format for our consumption, and experts routinely make predictions in a textual format (Christensen et al., 2004; Tetlock&Gardner, 2015; Frick, 2015). However, there has been relatively little formalization of this general problem in the machine learning or natural language processing communities. To address this gap, we introduce the task of future language modeling: probabilistic modeling of texts in the future based on a temporal history of texts. To our knowledge, our work is the first work to formalize the task of predicting the future in this way. We show that it is indeed possible to build future language models that improve upon strong non-temporal language model baselines, opening the door to working on this important, and widely applicable problem.", "citations": 0}
{"title": "Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency", "year": 2025, "authors": "Jiangxuan Long, Zhao Song, Chiwun Yang", "url": "https://api.semanticscholar.org/CorpusId:277103662", "relevance": 1, "abstract": "Recent studies suggest utilizing generative models instead of traditional auto-regressive algorithms for time series forecasting (TSF) tasks. These non-auto-regressive approaches involving different generative methods, including GAN, Diffusion, and Flow Matching for time series, have empirically demonstrated high-quality generation capability and accuracy. However, we still lack an appropriate understanding of how it processes approximation and generalization. This paper presents the first theoretical framework from the perspective of flow-based generative models to relieve the knowledge of limitations. In particular, we provide our insights with strict guarantees from three perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and $\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as follows: $\\bullet$ By assuming a general data model, the fitting of the flow-based generative models is confirmed to converge to arbitrary error under the universal approximation of Diffusion Transformer (DiT). $\\bullet$ Introducing a polynomial-based regularization for flow matching, the generalization error thus be bounded since the generalization of polynomial approximation. $\\bullet$ The sampling for generation is considered as an optimization process, we demonstrate its fast convergence with updating standard first-order gradient descent of some objective.", "citations": 2}
{"title": "Beam Prediction Based on Large Language Models", "year": 2024, "authors": "Yucheng Sheng, Kai Huang, Le Liang, Peng Liu, Shi Jin, Geoffrey Ye Li", "url": "https://www.semanticscholar.org/paper/7e9e805f8ed8780772b277a80e10dd1b4df65c20", "relevance": 1, "abstract": "In this letter, we use large language models (LLMs) to develop a high-performing and robust beam prediction method. We formulate the millimeter wave (mmWave) beam prediction problem as a time series forecasting task, where the historical observations are aggregated through cross-variable attention and then transformed into text-based representations using a trainable tokenizer. By leveraging the prompt-as-prefix (PaP) technique for contextual enrichment, our method harnesses the power of LLMs to predict future optimal beams. Simulation results demonstrate that our LLM-based approach outperforms traditional learning-based models in prediction accuracy as well as robustness, highlighting the significant potential of LLMs in enhancing wireless communication systems.", "citations": 48}
{"title": "ST-LLM+: Graph Enhanced Spatio-Temporal Large Language Models for Traffic Prediction", "year": 2025, "authors": "Chenxi Liu, K. H. Hettige, Qianxiong Xu, Cheng Long, Shili Xiang, Gao Cong, Ziyue Li, Rui Zhao", "url": "https://www.semanticscholar.org/paper/70751991fb3ba7693ada8f048fe5668b751e6553", "relevance": 1, "abstract": "Traffic prediction is a crucial component of data management systems, leveraging historical data to learn spatio-temporal dynamics for forecasting future traffic and enabling efficient decision-making and resource allocation. Despite efforts to develop increasingly complex architectures, existing traffic prediction models often struggle to generalize across diverse datasets and contexts, limiting their adaptability in real-world applications. In contrast to existing traffic prediction models, large language models (LLMs) progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose ST-LLM+, the graph enhanced spatio-temporal large language models for traffic prediction. Through incorporating a proximity-based adjacency matrix derived from the traffic network into the calibrated LLMs, ST-LLM+ captures complex spatio-temporal dependencies within the traffic network. The Partially Frozen Graph Attention (PFGA) module is designed to retain global dependencies learned during LLMs pre-training while modeling localized dependencies specific to the traffic domain. To reduce computational overhead, ST-LLM+ adopts the LoRA-augmented training strategy, allowing attention layers to be fine-tuned with fewer learnable parameters. Comprehensive experiments on real-world traffic datasets demonstrate that ST-LLM+ outperforms state-of-the-art models. In particular, ST-LLM+ also exhibits robust performance in both few-shot and zero-shot prediction scenarios. Additionally, our case study demonstrates that ST-LLM+ captures global and localized dependencies between stations, verifying its effectiveness for traffic prediction tasks.", "citations": 24}
{"title": "Traj-LLM: A New Exploration for Empowering Trajectory Prediction With Pre-Trained Large Language Models", "year": 2025, "authors": "Zhengxing Lan, Lingshan Liu, Bo Fan, Yisheng Lv, Yilong Ren, Zhiyong Cui", "url": "https://www.semanticscholar.org/paper/27acd33efb03849a54382b9e913a97b4abffa2fc", "relevance": 1, "abstract": "Predicting the future trajectories of dynamic traffic actors is a cornerstone task in autonomous driving. Though existing notable efforts have resulted in impressive performance improvements, a gap persists in scene cognitive and understanding of complex traffic semantics. This paper proposes Traj-LLM, the first to investigate the potential of using pre-trained Large Language Models (LLMs) without explicit prompt engineering to generate future motions from vehicular past trajectories and traffic scene semantics. Traj-LLM starts with sparse context joint encoding to dissect the agent and scene features into a form that LLMs understand. On this basis, we creatively explore LLMs' strong understanding capability to capture a spectrum of high-level scene knowledge and interactive information. To emulate the human-like lane focus cognitive function and enhance Traj-LLM's scene comprehension, we introduce lane-aware probabilistic learning powered by the Mamba module. Finally, a multi-modal Laplace decoder is designed to achieve scene-compliant predictions. Extensive experiments manifest that Traj-LLM, fueled by prior knowledge and understanding prowess of LLMs, together with lane-aware probability learning, transcends the state-of-the-art methods across most evaluation metrics. Moreover, the few-shot analysis serves to substantiate Traj-LLM's performance, as even with merely 50% of the dataset, it surpasses the majority of benchmarks relying on complete data utilization. This study explores endowing the trajectory prediction task with advanced capabilities inherent in LLMs, furnishing a more universal and adaptable solution for forecasting agent movements in a new way.", "citations": 51}
{"title": "FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting", "year": 2024, "authors": "Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Qingsong Wen, Christian S. Jensen, Bin Yang", "url": "https://www.semanticscholar.org/paper/c245a7d561855d7bef6c758e45e772129b52dacb", "relevance": 1, "abstract": "", "citations": 17}
{"title": "Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models", "year": 2024, "authors": "Zizhang Chen, Peizhao Li, Xiaomeng Dong, Pengyu Hong", "url": "https://api.semanticscholar.org/CorpusId:273850159", "relevance": 1, "abstract": "To facilitate healthcare delivery, language models (LMs) have significant potential for clinical prediction tasks using electronic health records (EHRs). However, in these high-stakes applications, unreliable decisions can result in high costs due to compromised patient safety and ethical concerns, thus increasing the need for good uncertainty modeling of automated clinical predictions. To address this, we consider uncertainty quantification of LMs for EHR tasks in both white-box and black-box settings. We first quantify uncertainty in white-box models, where we have access to model parameters and output logits. We show that an effective reduction of model uncertainty can be achieved by using the proposed multi-tasking and ensemble methods in EHRs. Continuing with this idea, we extend our approach to black-box settings, including popular proprietary LMs such as GPT-4. We validate our framework using longitudinal clinical data from over 6,000 patients across ten clinical prediction tasks. Results show that ensembling methods and multi-task prediction prompts reduce uncertainty across different scenarios. These findings increase model transparency in white-box and black-box settings, thereby advancing reliable AI healthcare. Our code is publically available at https://github.com/Cyrus9721/EHR_Uncertainty.", "citations": 3}
{"title": "EventTSF: Event-Aware Non-Stationary Time Series Forecasting", "year": 2025, "authors": "Yunfeng Ge, Ming Jin, Yiji Zhao, Hongyan Li, Bo Du, Chang Xu, Shirui Pan", "url": "https://www.semanticscholar.org/paper/d93a40fa5e0c9b82ecb971b4ec89fbb603e0abf7", "relevance": 1, "abstract": "Time series forecasting plays a vital role in critical domains like energy and transportation, where non-stationary dynamics are deeply intertwined with events in other modalities such as texts. However, incorporating natural language-based external events to improve non-stationary forecasting remains largely unexplored, as most approaches still rely on a single modality, resulting in limited contextual knowledge and model underperformance. Enabling fine-grained multimodal interactions between temporal and textual data is challenged by three fundamental issues: (1) the difficulty of fine-grained synchronization between time-varying discrete textual events and continuous time series; (2) the inherent temporal uncertainty introduced by textual semantics; and (3) the misalignment between textual event embeddings and multi-resolution temporal patterns. In this work, we address these challenges by introducing event-aware non-stationary time series forecasting (EventTSF), an autoregressive generation framework that integrates historical time series with textual events to make subsequent forecasts. Specifically, EventTSF uses autoregressive diffusion with flow matching at each step to capture nuanced temporal-event interactions. To handle event-induced uncertainty, flow matching timesteps are adaptively controlled according to event semantic signals. The underlying denoiser employs a multimodal U-shaped diffusion transformer that efficiently fuses temporal and textual modalities across different resolutions. Extensive experiments on 8 synthetic and real-world datasets show that EventTSF outperforms 12 baselines across diverse event-aware non-stationary time series forecasting scenarios, achieving substantial improvements of 10.7% higher forecasting accuracy and $1.13\\times$ faster training efficiency.", "citations": 0}
{"title": "Modeling and optimization of virtual power plant energy market behavior based on news sentiment and natural semantic analysis", "year": 2025, "authors": "Houqi Chen, Chen Shi, Mengyi Xu, Yanjia Wang, Xianlong Li, Xitian Wang, Chenghong Gu, Da Xie", "url": "https://www.semanticscholar.org/paper/f5454cfce7eab7f3c7523f27f63500ba1a5b565f", "relevance": 1, "abstract": "", "citations": 0}
